{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import pandas as pd\n",
    "np.random.seed(1)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "iris = sklearn.datasets.load_iris()\n",
    "\n",
    "print(type(iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwsklEQVR4nO3df3BV9Z3/8dfNxQRYSRTL7xuIm1KspQoLSIOL6BbLWsaGpVRsq4DWzmwJFswQ2jiubvttjRusq50Vf80KnToutSRAF1eUoiCrOApsZsBfC4iQYoJ0qzcEKGmT8/3jNIFL7j33x7knn3PufT6cOzHnnM85n3NgvG/v/Xw+r5BlWZYAAAAMKTDdAQAAkN8oRgAAgFEUIwAAwCiKEQAAYBTFCAAAMIpiBAAAGEUxAgAAjKIYAQAARvUz3YFUdHV16aOPPtKgQYMUCoVMdwcAAKTAsiydOHFCI0eOVEFB4s8/AlGMfPTRRyotLTXdDQAAkIHm5mZFIpGE+wNRjAwaNEiSfTPFxcWGewMAAFLR1tam0tLSnvfxRAJRjHR/NVNcXEwxAgBAwCQbYsEAVgAAYBTFCAAAMIpiBAAAGEUxAgAAjKIYAQAARlGMAAAAoyhGAACAURQjAADAqEAsegYAyA+dndKOHVJLizRihDR9uhQO9825vbw2nKX1yUhdXZ2mTJmiQYMGaejQoZozZ47ef/99xzZr1qxRKBSKefXv399VpwEAuaexUSork667TvrWt+yfZWX2dq/P7eW1kVxaxcj27dtVVVWlN954Q1u2bNGf/vQnfeUrX9HJkycd2xUXF6ulpaXndfjwYVedBgDklsZGad486Xe/i91+9Ki93U1RkOzcK1Z4d22kJmRZlpVp4+PHj2vo0KHavn27rrnmmrjHrFmzRsuWLdOnn36a6WXU1tamkpISRaNRsmkAIMd0dtqfQpxfDHQLhaRIRDp0KP2vTZKdW7LP2dmZ/Wsj9fdvVwNYo9GoJGnw4MGOx7W3t2vMmDEqLS1VZWWl3n77bcfjz5w5o7a2tpgXACA37djhXCxYltTcbB+X7XNLiQsRt9dG6jIuRrq6urRs2TJdffXVGj9+fMLjxo0bp6efflobN27UM888o66uLk2bNk2/c/jbUVdXp5KSkp5XaWlppt0EAPhcS0t2j3PbxsvzIL6Mi5Gqqirt27dPa9eudTyuoqJCCxYs0IQJEzRjxgw1NjZqyJAheuKJJxK2qa2tVTQa7Xk1Nzdn2k0AgM+NGJHd49y28fI8iC+jqb1LlizRpk2b9OqrryoSiaTV9oILLtDEiRN14MCBhMcUFRWpqKgok64BAAJm+nR7XMbRo/bXIufrHrcxfXr2zy3ZY0G6urJ/baQurU9GLMvSkiVLtH79er388su69NJL075gZ2en9u7dqxGUmQAA2cXAI4/Y/x4Kxe7r/v3hhzMbQJrs3KGQVF3tzbWRurSKkaqqKj3zzDN69tlnNWjQILW2tqq1tVWnT5/uOWbBggWqra3t+f3HP/6xXnrpJX3wwQfas2ePbrnlFh0+fFh33HFH9u4CABBoc+dK69ZJo0bFbo9E7O1z53p37vp6766N1KQ1tTd0ftn4F6tXr9aiRYskSddee63Kysq0Zs0aSdJdd92lxsZGtba26uKLL9akSZP0k5/8RBMnTky5k0ztBYD8wAqsuSXV929X64z0FYoRAACCp0/WGQEAAHCLYgQAABhFai8A5Ci/joHo6JBWrZIOHpTKy6XFi6XCQtO9gkkUIwCQgxobpaVLY5dCj0Tsaa4mZ4esWCE99FDsEuzLl9vTa+vrzfULZvE1DQDkGC8TcN1YsUJaubJ3Fkxnp719xQoz/YJ5zKYBgBziZQKuGx0d0sCBzqF04bB06hRf2eQSZtMAQB7yMgHXjVWrnAsRyd6/alXf9Af+QjECADnEywRcNw4ezO5xyC0UIwCQQ7xMwHWjvDy7xyG3MGYEAHJI95iRZAm4jBlBX2DMCADkIS8TcN0oLDybjptIdTWFSL6iGAGAHONlAq4b9fVSTU3vQigctrezzkj+4msaAMhRrMAK00jtBQAARjFmBAAABALFCAAAMIqgPADIUU5jRpKNJ3G734s+e93er2NsvOSbe7YCIBqNWpKsaDRquisAEAgNDZYViViWvdqI/YpE7O1O+5K1TWW/F332ur1X9+RnfXHPqb5/U4wAQI5paLCsUCj2TUaKv+3cfaGQZdXUJG6byv5M38ic+pzKed20d3vtIOqre071/ZvZNACQQ5Kl9joJhaSCguSrpCban+nqrm6Tht2092vKsZf68p6ZTQMAeShZaq8Ty0otWdepfSaJwG6Tht2092vKsZf8eM8UIwCQQ/o6jTcbfXCbNOymvV9Tjr3kx3umGAGAHNLXabzZ6IPbpGE37f2acuwlP94zY0YAIIckS+11kuqYka6u7CYCu00adtPerynHXurLe2bMCADkoVRSe532VVfb/x5vfyh0Nnk3m4nAbpOG3bT3a8qxl/x4zxQjAJBjnFJ7GxrsV6JE3/p658TfZPszTQR2mzTspr1fU4695Ld75msaAMhRrMDKCqzJeH3PpPYCAACjGDMCAAACgWIEAAAYRWovAKBPMa4ju3LhmVCMAAD6TGOjtHRp7HLkkYg91TTZDA43bXNVrjwTvqYBAPSJxkZp3rzeuShHj9rbGxu9aZurcumZMJsGAOA5knWzKyjPhNk0AADfIFk3u3LtmVCMAAA8R7JuduXaM6EYAQB4jmTd7Mq1Z0IxAgDw3PTp9hiG84PZuoVCUmmpfVw22+aqXHsmFCMAAM+RrJtdufZMKEYAAH2CZN3syqVnwtReAECfYgXW7PLzMyG1FwAAGMU6IwAAIBAoRgAAgFEE5QEA0uY0TiHZGAY3bd30K6hy8Z7ORzECAEiLU1Ks5Jwi66atm34FaWbJuXLxnuJhACsAIGXdSbHnv3OEQr23nbtPkpYvlx58MLO2yaaqOvUrlfZ+lAv3xGwaAEBWJUuKTSYcts+RrmQJtEFJsE1HrtwTs2kAAFmVLCk2mUwKESl5Am2uJdhKuXlPTihGAAApMZ0Am+j6uZZgK+XmPTmhGAEApMR0Amyi6+dagq2Um/fkhGIEAJCSZEmxyYTDmbVNlkCbawm2Um7ekxOKEQBASlJJik20LxSSqqszays5J9DmWoKtlJv35IRiBACQMqek2IYG+5UoRba+PvO2yaaw5lKCbbdcvKdEmNoLAEgbK7D2nSDfE+uMAAAAo1hnBAAABALFCAAAMIqgPADwKTdjL5LtD/I4hCDy8nnnxJ+llYb777/fmjx5snXhhRdaQ4YMsSorK6333nsvabvnnnvOGjdunFVUVGSNHz/eev7559O5rBWNRi1JVjQaTasdAARVQ4NlRSKWZS/8bb8iEXu72/3J2iK7vHzefv+zTPX9O61iZNasWdbq1autffv2WU1NTdZXv/pVa/To0VZ7e3vCNq+99poVDoet+vp665133rHuuece64ILLrD27t2b8nUpRgDkk4YGywqFYt9gJHtbKGRZNTWZ7z9/2/lt/fImliuS/Vm6ed5enjtbUn3/djWb5vjx4xo6dKi2b9+ua665Ju4x8+fP18mTJ7Vp06aebV/60pc0YcIEPf744yldh9k0APJFKmmtBQWJQ+eS7XcSlCTYoPAyeTcoqb59MpsmGo1KkgYPHpzwmJ07d2rmzJkx22bNmqWdO3cmbHPmzBm1tbXFvAAgH6SS1upUaCTb7yTXkmBN8zJ5N9dSfTMuRrq6urRs2TJdffXVGj9+fMLjWltbNWzYsJhtw4YNU2tra8I2dXV1Kikp6XmVlpZm2k0ACBQ/pLD6oQ+5wMvk3VxL9c24GKmqqtK+ffu0du3abPZHklRbW6toNNrzam5uzvo1AMCP/JDC6oc+5AIvk3dzLdU3o2JkyZIl2rRpk1555RVFIhHHY4cPH65jx47FbDt27JiGDx+esE1RUZGKi4tjXgCQD1JJa3UaA5Bsv5NcS4I1zcvk3VxL9U2rGLEsS0uWLNH69ev18ssv69JLL03apqKiQlu3bo3ZtmXLFlVUVKTXUwDIA6mktVZXn03CzWS/07lzKQnWNC+Td3Mu1TedKTrf+973rJKSEmvbtm1WS0tLz+vUqVM9x9x6663WD3/4w57fX3vtNatfv37Wgw8+aL377rvWfffdx9ReAEgi3voRpaXO64ikuj9ZW2SXl8/b73+WnkztDSX4PGj16tVatGiRJOnaa69VWVmZ1qxZ07P/17/+te655x59+OGHGjt2rOrr6/XVr3415YKJqb0A8hErsOaOfF2BldReAABgFKm9AAAgEChGAACAUaT2AkBAJRsr0NEhrVolHTwolZdLixdLhYXZOXcuysd79guKEQAIoMZGaenS2CXBIxF7uufcudKKFdJDD8UuDb98uT3tt77e3blzUT7es58wgBUAAqaxUZo3z57Iea7uCY9f+5q0cWPi9jU1iQuSZOdety733pzz8Z77CrNpACAHpZLWmuy/6uGwdOpU769sgpIEm035eM99idk0AJCDUklrTaaz0x5Lksm5g5QEm4p8vGc/ohgBgADJVgrrwYOZnzsoSbCpyMd79iOKEQAIkGylsJaXZ37uoCTBpiIf79mPGDMCAAHSPcbh6NH4X8lkY8yI07lzbfxEPt5zX2LMCADkoFTSWisrnc9RXR1/vZGcS4JNQT7esx9RjABAwMyda083HTUqdnskYm/fsMGevnv+G2g47DytN5Vz5+IU13y8Z7/haxoACChWYM2ufLxnr7HOCAAAMIoxIwAAIBAoRgAAgFEE5QGAQaf/2Kma+w9p//4ujR1boJV3X6oB/e2BCm7GfEjmxkAk67ebfplqa/LcecEKgGg0akmyotGo6a4AQNZU3v6epdCfLXuFi7+8Qn+2Km9/z6qpsaxw2IrZFw5bVk1NauduaLCsSCS2fSRib/dSsn676ZeptibPHXSpvn9TjACAAZW3v2dJXX95nftG1pVg+9lXsoKkocGyQqHe7UIh++XVm2RNTfz+dr8qKzPvl5t78vJ5mHrWQZHq+zezaQCgj53+Y6cGDpRkFUgKxTmi+z/L8fYlXkFVMpdC29EhDRxoXz8TTv1yc09ePg8Sf5NjNg0A+FTN/YckK6xExYa9PdG+xKm7krkU2lWrMi9EJOd+ubknL58Hib/ZQzECAH1s//4u1+eIl7ormUuhTdSfdMXrl5t78vJ5kPibPRQjANDHxo51/5/eeKm7krkU2kT9SVe8frm5Jy+fB4m/2cOYEQDoY30xZqSvU2j7YsxIJvfk5fMg8Tc5xowAgE8N6B9W5W0H/vLb+e9iyf//MFHqrmQuhbaw0O6Xk8pKuw/p9svNPXn5PEj8zaI+mNnjGlN7AeSi+OuM/MmzdUZKS/25zkiq/TLV1uS5g46pvQAQAKzAygqsuYzUXgAAYBRjRgAAQCBQjAAAAKNI7QWAJPw6HqCzq1M7juxQy4kWjRg0QtNHT1e4wAcdA9JEMQIADhobpaVLY5f9jkTsKZ1z5xrs17uNWrp5qX7XdrZjkeKIHvn7RzT38wY7BmSAr2kAIIHGRmnevN75I0eP2tsbGw31691GzXtuXkwhIklH245q3nPz1PiuoY4BGaIYAYA4OjvtT0TizTfs3rZsmbtwuEx0dnVq6ealsuIsjta9bdnmZers6uOOAS5QjABAHH5NZN1xZEevT0TOZclSc1uzdhwhKhbBQTECAHH4NZG15URqF0z1OMAPKEYAIA6/JrKOGJTaBVM9DvADihEAiGP6dHvWzPkBaN1CIam01D6uT/s1eroixRGFEiT6hhRSaXGppo/u444BLlCMAEAcfk1kDReE9cjf2x07vyDp/v3hv3+Y9UYQKBQjAJDA3LnSunXSqFGx2yMRe7updUbmfn6u1t20TqOKYzsWKY5o3U3rWGcEgUNQHgAkwQqsQGZSff9mBVYASCIclq691nQvegsXhHVt2bWmuwG4xtc0AADAKIoRAABgFF/TAEASbsZmmBzXkYtjSvw6fgfuUIwAgAM36bgmk3VzMdXXrwnKcI/ZNACQQHc67vmhdN3reThNo3XT1i2T1/ZKd4Ly+e9Y3Wu+mJxqjcRSff+mGAGAODq7OlX2SFnCULqQQooUR3Ro6aFeX324aWuy337V2SmVlSUOLgyF7E9IDh3iKxu/SfX9mwGsABCHm3Rck8m6uZjq69cEZWQPxQgAxOEmHddksm4upvr6NUEZ2UMxAgBxuEnHNZmsm4upvn5NUEb2UIwAQBxu0nFNJuvmYqqvXxOUkT0UIwAQh5t0XJPJurmY6uvXBGVkD8UIACTgJh3XZLJuLqb6+jVBGdnB1F4ASIIVWP2DFViDhXVGAACAUawzAgAAAoFiBAAAGEVQHoCc4OX4iOipqGavna0j0SMaXTJaz9/8vEoGlqR0XTf96vhzh1btWqWDfzio8sHlWjx5sQr7FZ49d5LxE4yvQFCkPWbk1Vdf1cqVK7V79261tLRo/fr1mjNnTsLjt23bpuuuu67X9paWFg0fPjylazJmBIATLxNqP/vzz+rgJwd7bS+/uFz119c7XtdNv1ZsWaGHdj6kTquzZ1s4FFZ1RbXqr69PmmBLwi38wLMBrC+88IJee+01TZo0SXPnzk25GHn//fdjOjJ06FAVFKT2LRHFCIBEvEyoTVSIOOm+7vJpy/Xg6w9m1K8VW1Zo5esrE16jsusX+s3/W5AwwXb5cunBB0m4hXl9MpsmFAqlXIx88sknuuiiizK6DsUIgHi8TKiNnorqopUXZdy3cCgc86lGqv3q+HOHBt4/MGFbdRVID38otUWkBKushsP2VzRxr03CLfqQ72bTTJgwQSNGjND111+v1157zfHYM2fOqK2tLeYFAOfzMqF29trZbrqWuJiQc79W7Vrl2FaHp0ttpUpUiEiJCxGJhFv4k+fFyIgRI/T444+roaFBDQ0NKi0t1bXXXqs9e/YkbFNXV6eSkpKeV2lpqdfdBBBAXibUHokeSbtNuuL16+Afknwt1J6dNDgSbuEnns+mGTdunMaNG9fz+7Rp03Tw4EH967/+q375y1/GbVNbW6vq6uqe39va2ihIAPTiZULt6JLRam5rTrtdOuL1q3xwuXOjC7NTRZBwCz8xss7IVVddpQMHDiTcX1RUpOLi4pgXAJzPy4Ta529+3lXfwqFwRv1aPHmxwiGHwRxjdkjFzQqFEg/3C4dJuEWwGClGmpqaNIKyHIBLXibUlgwsUfnFST6lSHDdkEKqrqjOqF+F/Qp72sZV0KXKZa/YZ4qTYBsKSd0fLJNwi6BIuxhpb29XU1OTmpqaJEmHDh1SU1OTjhyxv1+tra3VggULeo5/+OGHtXHjRh04cED79u3TsmXL9PLLL6uqqio7dwAgr3mZUHvg+wcSFiTlF5er4aaGhNetv74+437VX1+vmmk1vT4hCYfCqplWow0/WuCYYFtfT8ItgiXtqb2JFjFbuHCh1qxZo0WLFunDDz/Utm3bJEn19fV68skndfToUQ0cOFBXXHGF7r333rjnSISpvQCSYQVWVmCF/5DaCwAAjPLdOiMAAADxUIwAAACjSO0F0Ge8HNfhRrKxGU6S3VPScR8+fSZeYiwLzseYEQB9wstkXTeSpeM6SXZPSZN3ffpMvESacH5hACsA3/AyWdeNZOm4NdNqEhYkye7pa+O+po3vb0x47spxlfrN+7/x3TPxUmOjNG8eacL5hGIEgC94mazrRtJ0XNmfYpy6+1Svr2xSuafzi4x0mHomXurslMrKYj8RORdpwrmJ2TQAfMHLZF03kqbjyk7eXbVrVa/tqdyTG6aeiZd27EhciEikCec7ihEAnvIyWdeNpOm4Dsf1VV/7+pl4KdWUYNKE8xPFCABPeZms60bSdFyH4/qqr339TLyUahwZsWX5iWIEgKe8TNZ1I2k6ruwxI4snL+61PZV7SoXfnomXpk+3x4SQJox4KEYAeMrLZF03kqbjSqquqI673kgq91Q5rtLx3N37/fRMvBQO29N3JdKE0RvFCADPeZms60aydFyndUaS3dOGmzc4J+/evMGXz8RLc+eSJoz4mNoLoM/4dbVRVmDtW6zAmj9YZwQAABjFOiMAACAQKEYAAIBRpPYCiGFyDMPpjtOq+W2N9v/ffo29ZKxWzlypAYUDJCUfe+G03+24Daf9+TjmA8g2xowA6GEyRXbO2jlxg+Uqx1Xqc5d8zjH91ikdV5Kr5Fyn/ZLyLnUXSAcDWAGkxWSybqJCJBVTRk7RWx+9lVHbZMm5y6ct14OvPxh3f6L8mVxO3QXSRTECIGUmk3VPd5zWwLqBWT1nNoQUUkGoIGmYXqK2uZa6C2SC2TQAUmYyWbfmtzVZP2c2WLIyKkS62+Za6i7gJYoRAEaTdff/3/6sn9Mvcil1F/ASxQgAo8m6Yy8Zm/Vz+kUupe4CXqIYAWA0WXflzJVZP2c2hBRKmurr1DbXUncBL1GMADCarDugcEDShFsnU0ZOybht5bhKhf7yz7m6f6+uqHbcf/6/n/t7rqXuAl6iGAEgyWyy7oabNyQsSCrHVTqm37753Tcd97tJzq2/vj7h/oabGtRwU0Nepe4CXmFqL4AYrMDKCqxAtrDOCAAAMIp1RgAAQCBQjAAAAKNI7QXQZ9yMzXB7bq/amjw3kCsoRgD0CTfpuMlmpphqm4zJFGQgSBjACsBzyRKBndJxJecEXDdpw14mFZtMQQb8gtk0AHwhWSKwZK/7kSiUzikB103asJdJxSZTkAE/YTYNAF9IlggsyTEd1ykB103asJdJxSZTkIEgohgB4KlsJdfGO4+btGEvk4pNpiADQUQxAsBT2UqujXceN2nDXiYVm0xBBoKIYgSAp5IlAkv2mJFMEoPdpA17mVRsMgUZCCKKEQCeSpYIHFJI1RXVCfdLiRNw3aQNe5lUbDIFGQgiihEAnkuWCOyUjptsCqybtGEvk4pNpiADQcPUXgB9hhVYWYEV+YV1RgAAgFGsMwIAAAKBYgQAABhFUB7gkXwcK+DlmBAAuYtiBPBAPqa1epnKCyC3MYAVyLJ8TGv1MpUXQHAxmwYwIB/TWlO554JQQUapvACCjdk0gAH5mNaayj1nmsoLID9QjABZlI9prV6m8gLIDxQjQBblY1qrl6m8APIDxQiQRfmY1prKPYdDiceC5OIzAZAeihEgi/IxrTWVe66uqO5J6I23P9eeCYD0UIwAWZaPaa1epvICyH1M7QU8ko+rjbICK4Bzsc4IAAAwinVGAABAIFCMAAAAowjKAwKo488dWrVrlQ7+4aDKB5dr8eTFKuxX6HlbydtxH07nZrwJkLvSHjPy6quvauXKldq9e7daWlq0fv16zZkzx7HNtm3bVF1drbffflulpaW65557tGjRopSvyZgR4KwVW1booZ0PxSyxHg6FVV1Rrfrr6z1rK3mbRux0bkkk/gIB5NmYkZMnT+rKK6/Uo48+mtLxhw4d0uzZs3XdddepqalJy5Yt0x133KEXX3wx3UsDeW/FlhVa+frKXlkvnVanVr6+Uiu2rPCkrXQ2mff8HJqjbUc177l5any3Mc27Se3cX3/u6/r6c1/35LoA/MHVbJpQKJT0k5Ef/OAHev7557Vv376ebTfffLM+/fRTbd68OaXr8MkIYH+9MvD+gY6hc+FQWKfuPtXraxc3bSVv04iTndsJib+Av/lmNs3OnTs1c+bMmG2zZs3Szp07E7Y5c+aM2traYl5Avlu1a5VjMSHZn3Ks2rUqq20lb9OIk53bCYm/QG7wvBhpbW3VsGHDYrYNGzZMbW1tOn36dNw2dXV1Kikp6XmVlpZ63U3A9w7+4WDGx7lpK3mbRpyNtF4Sf4Fg8+XU3traWkWj0Z5Xc3Oz6S4BxpUPLs/4ODdtJW/TiLOR1kviLxBsnhcjw4cP17Fjx2K2HTt2TMXFxRowYEDcNkVFRSouLo55Aflu8eTFjum3kj3uY/HkxVltK3mbRpzs3E5I/AVyg+fFSEVFhbZu3RqzbcuWLaqoqPD60kBOKexXqOqKasdjqiuq4w5AddNW8jaNOJVze3FdAP6RdjHS3t6upqYmNTU1SbKn7jY1NenIkSOS7K9YFixY0HP8P/7jP+qDDz7QihUr9N5772nVqlV67rnndNddd2XnDoA8Un99vWqm1fT6lCMcCqtmWo3jWiFu2krephE7nbvhpgY13NRA4i+Qw9Ke2rtt2zZdd911vbYvXLhQa9as0aJFi/Thhx9q27ZtMW3uuusuvfPOO4pEIvqnf/onFj0DXGAFVlZgBYKA1F4AAGCUb9YZAQAAcEIxAgAAjKIYAQAARlGMAAAAoyhGAACAURQjAADAKIoRAABgFMUIAAAwimIEAAAYRTECAACMohgBAABGUYwAAACjKEYAAIBRFCMAAMAoihEAAGAUxQgAADCKYgQAABhFMQIAAIyiGAEAAEZRjAAAAKMoRgAAgFEUIwAAwCiKEQAAYBTFCAAAMIpiBAAAGEUxAgAAjKIYAQAARlGMAAAAoyhGAACAURQjAADAKIoRAABgFMUIAAAwimIEAAAYRTECAACMohgBAABGUYwAAACjKEYAAIBRFCMAAMAoihEAAGAUxQgAADCKYgQAABhFMQIAAIyiGAEAAEZRjAAAAKP6me4A0tTZKe3YIbW0SCNGSNOnS+Gw6V4BAJAxipEgaWyUli6Vfve7s9siEemRR6S5c831CwAAF/iaJigaG6V582ILEUk6etTe3thopl8AALhEMRIEnZ32JyKW1Xtf97Zly+zjAAAIGIqRINixo/cnIueyLKm52T4OAICAoRgJgpaW7B4HAICPUIwEwYgR2T0OAAAfoRgJgunT7VkzoVD8/aGQVFpqHwcAQMBQjARBOGxP35V6FyTdvz/8MOuNAAACiWIkKObOldatk0aNit0eidjbWWcEABBQLHoWJHPnSpWVrMAKAMgpFCNBEw5L115ruhcAAGQNX9MAAACjKEYAAIBRfE2Ta0j1BQAETEafjDz66KMqKytT//79NXXqVL355psJj12zZo1CoVDMq3///hl3GA4aG6WyMum666Rvfcv+WVZGiB4AwNfSLkZ+9atfqbq6Wvfdd5/27NmjK6+8UrNmzdLHH3+csE1xcbFaWlp6XocPH3bVacRBqi8AIKDSLkYeeughffe739Vtt92myy+/XI8//rgGDhyop59+OmGbUCik4cOH97yGDRvmqtM4D6m+AIAAS6sY6ejo0O7duzVz5syzJygo0MyZM7Vz586E7drb2zVmzBiVlpaqsrJSb7/9tuN1zpw5o7a2tpgXHJDqCwAIsLSKkd///vfq7Ozs9cnGsGHD1NraGrfNuHHj9PTTT2vjxo165pln1NXVpWnTpul3Dm+edXV1Kikp6XmVlpam0838Q6ovACDAPJ/aW1FRoQULFmjChAmaMWOGGhsbNWTIED3xxBMJ29TW1ioajfa8mpubve5msJHqCwAIsLSm9n7mM59ROBzWsWPHYrYfO3ZMw4cPT+kcF1xwgSZOnKgDBw4kPKaoqEhFRUXpdC2/daf6Hj0af9xIKGTvJ9UXAOBDaX0yUlhYqEmTJmnr1q0927q6urR161ZVVFSkdI7Ozk7t3btXI/i/9Owh1RcAEGBpf01TXV2tp556Sr/4xS/07rvv6nvf+55Onjyp2267TZK0YMEC1dbW9hz/4x//WC+99JI++OAD7dmzR7fccosOHz6sO+64I3t3AVJ9AQCBlfYKrPPnz9fx48d17733qrW1VRMmTNDmzZt7BrUeOXJEBQVna5xPPvlE3/3ud9Xa2qqLL75YkyZN0uuvv67LL788e3cBG6m+AIAACllWvEEG/tLW1qaSkhJFo1EVFxeb7g4AAEhBqu/fBOUBAACjKEYAAIBRpPZ6wU1y7unTUk2NtH+/NHastHKlNGBA6ud2c20SfwEAJlgBEI1GLUlWNBo13ZXkGhosKxKxLHvFD/sVidjbk6msjG3X/aqsTO3cbq7tpi0AAHGk+v7NANZs6k7OPf+Rdq/14TTFds4caePGxOeeMkXatSvxuZcvlx58MLNru+k3AAAJpPr+TTGSLZ2dUllZ4sC67lVQDx3q/dXH6dPSwIGZXzsUkgoKEqfyOl3bTb8BAHDAbJq+5iY5t6bG3bUtK3EhkuzaJP4CAAyjGMkWN8m5+/dnty/pXJvEXwCAYRQj2eImOXfs2Oz2JZ1rk/gLADCMMSPZ0j32Illyrl/HjGTSbwAAHDBmpK+5Sc4dMMDOlHEyZYp9nkTnrq523p/o2iT+AgAMoxjJJjfJuRs2JC5IKiulN990Pnd9febXJvEXAGAQX9N4gRVYAQBgnREAAGAWY0YAAEAgUIwAAACjSO31QkeHtGqVdPCgVF4uLV4sFRae3e80LsTtuA3GfQAAAoYxI9m2YoX00EOxa36Ew/bU2/r6xIF4lZXSggXS0qWxy7NHIvbU21RmtDQ2umsPAEAWMYDVhBUr7E85Eikvtz8tSUeqybkk7wIAfIZipK91dNirqDoF1mUq2SqoJO8CAHyI2TR9bdUqbwoRKXlyLsm7AIAAoxjJlnS/fslEouRckncBAAFGMZIt5eXeXyNRci7JuwCAAKMYyZbFi70bjxEKSaWl9jTdeKZPt8eEnB90l2p7AAAMohjJlsJCe/quk1Q+PckkOZfkXQBAgFGMZFN9vb2Y2flv+uGwvf3AAedk3oaGzJNzSd4FAAQUU3u9wAqsAACwzggAADCLdUYAAEAgUIwAAACj8rcY6eyUtm2T/uM/7J/prp7a0WHPULnzTvtnR8fZfe3t0j/8g3TFFfbP9vbYtq2t0vDhUv/+9s/W1rP7jh+XLr1UuvBC++fx47Fto1Hpb/9WGj3a/hmNZu++3D4TAAAyYQVANBq1JFnRaDQ7J2xosKxIxLLshdLtVyRib09FTY1lhcOx7cNhe/uUKbHbu19TpthtBw6Mv3/gQMsqKYm/r6TEblteHn9/ebn7+3L7TAAAOE+q79/5N4DVbbptsmReJ6FQ7+tmq+2wYdLHH2d2XyT+AgA8wGyaeNym23qZzOslp/si8RcA4BFm08TjNt3Wy2ReLzndF4m/AADD8qsYcZtu2xfJvF6Kd18k/gIADMuvYsRtum1fJPN6Kd59kfgLADAsP8eMHD0afzBoPo8ZyfSZAACQAGNG4nGbbptKMq+T86+ZzbbDhtnHpHtfJP4CAAzLr2JEcp9umyyZd8qU+O2mTJG6uuxPVuIZOFAqKYm/r6TEbpvoa6LycnvhtEzvi8RfAIBB+fU1zbncpts6JfO2t0u33np23y9/aa+o2q21VZowQfr0U+mii6SmJnslVslecfWqq+yfQ4ZIb75p/+wWjUqzZ0tHjtirsD7/fGwR4+a+SPwFAGQR64wAAACjGDMCAAACgWIEAAAY1c90B3zLy/ETTuNNnPYBAJCDGDMST2OjtHRp7DLpkYg9BdbtzJIVK6SHHopdqyQcPjtlONG++np31wUAoI8xgDVTXibYukn8ramhIAEABArFSCa8TLB1u3prOCydOsVXNgCAwGA2TSa8TLB1m/jb2WmfAwCAHEMxci4vE2yzkfgb9NRgAADioBg5l5cJttlI/A16ajAAAHEwZuRcXibYMmYEAJBnGDOSCS8TbN0m/lZXU4gAAHISxcj5vEywTZb467SPab0AgBzF1zSJsAIrAACusM4IAAAwijEjAAAgEChGAACAURQjAADAqIyKkUcffVRlZWXq37+/pk6dqjfffNPx+F//+te67LLL1L9/f33xi1/Uf/3Xf2XUWQAAkHvSLkZ+9atfqbq6Wvfdd5/27NmjK6+8UrNmzdLHH38c9/jXX39d3/zmN/Wd73xH//M//6M5c+Zozpw52rdvn+vOAwCA4Et7Ns3UqVM1ZcoU/du//ZskqaurS6Wlpbrzzjv1wx/+sNfx8+fP18mTJ7Vp06aebV/60pc0YcIEPf744yldk9k0AAAEjyezaTo6OrR7927NnDnz7AkKCjRz5kzt3LkzbpudO3fGHC9Js2bNSni8JJ05c0ZtbW0xLwAAkJvSKkZ+//vfq7OzU8OGDYvZPmzYMLW2tsZt09ramtbxklRXV6eSkpKeV2lpaTrdBAAAAeLL2TS1tbWKRqM9r+bmZtNdAgAAHumXzsGf+cxnFA6HdezYsZjtx44d0/Dhw+O2GT58eFrHS1JRUZGKiop6fu8e1sLXNQAABEf3+3ay4alpFSOFhYWaNGmStm7dqjlz5kiyB7Bu3bpVS5YsidumoqJCW7du1bJly3q2bdmyRRUVFSlf98SJE5LE1zUAAATQiRMnVFJSknB/WsWIJFVXV2vhwoWaPHmyrrrqKj388MM6efKkbrvtNknSggULNGrUKNXV1UmSli5dqhkzZuhnP/uZZs+erbVr12rXrl168sknU77myJEj1dzcrEGDBikUCqXb5YTa2tpUWlqq5uZmZumkiGeWHp5X+nhm6eF5pYfnlT43z8yyLJ04cUIjR450PC7tYmT+/Pk6fvy47r33XrW2tmrChAnavHlzzyDVI0eOqKDg7FCUadOm6dlnn9U999yju+++W2PHjtWGDRs0fvz4lK9ZUFCgSCSSbldTVlxczF/KNPHM0sPzSh/PLD08r/TwvNKX6TNz+kSkWyBSe73C+iXp45mlh+eVPp5Zenhe6eF5pa8vnpkvZ9MAAID8kdfFSFFRke67776YmTtwxjNLD88rfTyz9PC80sPzSl9fPLO8/poGAACYl9efjAAAAPMoRgAAgFEUIwAAwCiKEQAAYFReFiOvvvqqbrzxRo0cOVKhUEgbNmww3SVfq6ur05QpUzRo0CANHTpUc+bM0fvvv2+6W7722GOP6YorruhZJKiiokIvvPCC6W4FxgMPPKBQKBQTI4FY//zP/6xQKBTzuuyyy0x3y9eOHj2qW265RZdccokGDBigL37xi9q1a5fpbvlWWVlZr79joVBIVVVVWb9WXhYjJ0+e1JVXXqlHH33UdFcCYfv27aqqqtIbb7yhLVu26E9/+pO+8pWv6OTJk6a75luRSEQPPPCAdu/erV27dunv/u7vVFlZqbffftt013zvrbfe0hNPPKErrrjCdFd87wtf+IJaWlp6Xv/93/9tuku+9cknn+jqq6/WBRdcoBdeeEHvvPOOfvazn+niiy823TXfeuutt2L+fm3ZskWS9I1vfCPr10p7OfhccMMNN+iGG24w3Y3A2Lx5c8zva9as0dChQ7V7925dc801hnrlbzfeeGPM7z/96U/12GOP6Y033tAXvvAFQ73yv/b2dn3729/WU089pZ/85Cemu+N7/fr1c0xAx1n/8i//otLSUq1evbpn26WXXmqwR/43ZMiQmN8feOABlZeXa8aMGVm/Vl5+MgJ3otGoJGnw4MGGexIMnZ2dWrt2rU6ePJlWWnU+qqqq0uzZszVz5kzTXQmE/fv3a+TIkfrrv/5rffvb39aRI0dMd8m3fvOb32jy5Mn6xje+oaFDh2rixIl66qmnTHcrMDo6OvTMM8/o9ttvz2pgbbe8/GQEmevq6tKyZct09dVXpxV2mI/27t2riooK/fGPf9SFF16o9evX6/LLLzfdLd9au3at9uzZo7feest0VwJh6tSpWrNmjcaNG6eWlhb96Ec/0vTp07Vv3z4NGjTIdPd854MPPtBjjz2m6upq3X333Xrrrbf0/e9/X4WFhVq4cKHp7vnehg0b9Omnn2rRokWenJ9iBGmpqqrSvn37+G46BePGjVNTU5Oi0ajWrVunhQsXavv27RQkcTQ3N2vp0qXasmWL+vfvb7o7gXDuV81XXHGFpk6dqjFjxui5557Td77zHYM986euri5NnjxZ999/vyRp4sSJ2rdvnx5//HGKkRT8+7//u2644QaNHDnSk/PzNQ1StmTJEm3atEmvvPKKIpGI6e74XmFhoT772c9q0qRJqqur05VXXqlHHnnEdLd8affu3fr444/1N3/zN+rXr5/69eun7du36+c//7n69eunzs5O0130vYsuukif+9zndODAAdNd8aURI0b0+h+Bz3/+83y1lYLDhw/rt7/9re644w7PrsEnI0jKsizdeeedWr9+vbZt28agrwx1dXXpzJkzprvhS1/+8pe1d+/emG233XabLrvsMv3gBz9QOBw21LPgaG9v18GDB3Xrrbea7oovXX311b2WJPjf//1fjRkzxlCPgmP16tUaOnSoZs+e7dk18rIYaW9vj/m/h0OHDqmpqUmDBw/W6NGjDfbMn6qqqvTss89q48aNGjRokFpbWyVJJSUlGjBggOHe+VNtba1uuOEGjR49WidOnNCzzz6rbdu26cUXXzTdNV8aNGhQrzFIf/VXf6VLLrmEsUkJLF++XDfeeKPGjBmjjz76SPfdd5/C4bC++c1vmu6aL911112aNm2a7r//ft10001688039eSTT+rJJ5803TVf6+rq0urVq7Vw4UL16+dhyWDloVdeecWS1Ou1cOFC013zpXjPSpK1evVq013zrdtvv90aM2aMVVhYaA0ZMsT68pe/bL300kumuxUoM2bMsJYuXWq6G741f/58a8SIEVZhYaE1atQoa/78+daBAwdMd8vX/vM//9MaP368VVRUZF122WXWk08+abpLvvfiiy9akqz333/f0+uELMuyvCt1AAAAnDGAFQAAGEUxAgAAjKIYAQAARlGMAAAAoyhGAACAURQjAADAKIoRAABgFMUIAAAwimIEAAAYRTECAACMohgBAABGUYwAAACj/j+z2eNuGLlg8QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(features[labels == 0,2], features[labels == 0, 3], c = 'r', label = 'Setosa')\n",
    "plt.scatter(features[labels == 1,2], features[labels == 1, 3], c = 'g', label = 'Versicolor')\n",
    "plt.scatter(features[labels == 2,2], features[labels == 2, 3], c = 'b', label = 'Virginica')\n",
    "plt.show()\n",
    "\n",
    "# # Visualizing only classes green and blue in 3d (in the first three features)\n",
    "# custom_colors = ['g', 'b']\n",
    "# cmap_custom = matplotlib.colors.ListedColormap(custom_colors)\n",
    "# fig = plt.figure(figsize=(10, 8))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(features[labels != 0,1], features[labels != 0,2], features[labels != 0,3], c = labels[labels != 0], cmap = cmap_custom)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving only the green and blue classes with features 2, and 3\n",
    "features = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "features = features[labels != 0] # Drop class 0\n",
    "features = features[:,2:] # Drop features 0 and 1\n",
    "\n",
    "labels = labels[labels != 0] # Drop class 0\n",
    "\n",
    "# # Checking that the results look correct\n",
    "# print(features.shape)\n",
    "# print(labels.shape)\n",
    "# custom_colors = ['g', 'b']\n",
    "# cmap_custom = matplotlib.colors.ListedColormap(custom_colors)\n",
    "# fig = plt.figure(figsize=(10, 8))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(features[:,0], features[:,1], features[:,2], c = labels, cmap = cmap_custom)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 2)\n",
      "(20, 2)\n",
      "(80, 1)\n",
      "(20, 1)\n",
      "torch.Size([80, 2])\n",
      "torch.Size([20, 2])\n",
      "torch.Size([80, 1])\n",
      "torch.Size([20, 1])\n",
      "tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1]])\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0]])\n"
     ]
    }
   ],
   "source": [
    "train, test, labels_train, labels_test = sklearn.model_selection.train_test_split(features, labels, train_size=0.80)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(labels_train.reshape(-1,1).shape)\n",
    "print(labels_test.reshape(-1,1).shape)\n",
    "\n",
    "train = torch.from_numpy(train)\n",
    "test = torch.from_numpy(test)\n",
    "labels_train = torch.from_numpy(labels_train).reshape(-1,1)\n",
    "labels_test = torch.from_numpy(labels_test).reshape(-1,1)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(labels_train.shape)\n",
    "print(labels_test.shape)\n",
    "\n",
    "labels_train = labels_train.remainder(2) # 'Relabels' class 2 as class 0 --> Now we have classes 0 and 1\n",
    "labels_test = labels_test.remainder(2) # 'Relabels' class 2 as class 0 --> Now we have classes 0 and 1\n",
    "\n",
    "print(labels_train[:5])\n",
    "print(labels_test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.1000, 1.9000],\n",
      "        [5.6000, 1.4000],\n",
      "        [5.1000, 1.6000],\n",
      "        [6.4000, 2.0000],\n",
      "        [5.9000, 2.3000],\n",
      "        [4.1000, 1.0000],\n",
      "        [4.7000, 1.5000],\n",
      "        [5.6000, 2.2000],\n",
      "        [5.0000, 1.5000],\n",
      "        [5.3000, 2.3000],\n",
      "        [5.1000, 1.9000],\n",
      "        [4.0000, 1.3000],\n",
      "        [4.5000, 1.7000],\n",
      "        [5.9000, 2.1000],\n",
      "        [5.1000, 1.9000],\n",
      "        [3.9000, 1.2000],\n",
      "        [3.7000, 1.0000],\n",
      "        [4.2000, 1.3000],\n",
      "        [5.6000, 2.1000],\n",
      "        [3.5000, 1.0000]], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(test)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtest_labels\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "class LogisticRegressor(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressor, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def class_probabilities(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.forward(x)\n",
    "            class_probs = torch.cat((1-x, x), dim = 1)\n",
    "        return class_probs.reshape(-1,2)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.forward(x)\n",
    "            predicted_class = x.detach().round()\n",
    "        return predicted_class.reshape(-1,1)\n",
    "\n",
    "model = LogisticRegressor(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 0.7195862531661987 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [2/500], Loss: 0.6781558394432068 Training accuracy = 0.574999988079071 | Test accuracy = 0.699999988079071\n",
      "Epoch [3/500], Loss: 0.6699885725975037 Training accuracy = 0.574999988079071 | Test accuracy = 0.4000000059604645\n",
      "Epoch [4/500], Loss: 0.6787610054016113 Training accuracy = 0.5249999761581421 | Test accuracy = 0.4000000059604645\n",
      "Epoch [5/500], Loss: 0.6820257902145386 Training accuracy = 0.5375000238418579 | Test accuracy = 0.4000000059604645\n",
      "Epoch [6/500], Loss: 0.6759358644485474 Training accuracy = 0.7124999761581421 | Test accuracy = 0.550000011920929\n",
      "Epoch [7/500], Loss: 0.6658673286437988 Training accuracy = 0.7875000238418579 | Test accuracy = 0.8999999761581421\n",
      "Epoch [8/500], Loss: 0.6571905016899109 Training accuracy = 0.512499988079071 | Test accuracy = 0.699999988079071\n",
      "Epoch [9/500], Loss: 0.6525575518608093 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [10/500], Loss: 0.6514542698860168 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [11/500], Loss: 0.6513108015060425 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [12/500], Loss: 0.6496552228927612 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [13/500], Loss: 0.6456345319747925 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6499999761581421\n",
      "Epoch [14/500], Loss: 0.6400078535079956 Training accuracy = 0.550000011920929 | Test accuracy = 0.75\n",
      "Epoch [15/500], Loss: 0.6342564225196838 Training accuracy = 0.6499999761581421 | Test accuracy = 0.75\n",
      "Epoch [16/500], Loss: 0.6296281218528748 Training accuracy = 0.824999988079071 | Test accuracy = 0.800000011920929\n",
      "Epoch [17/500], Loss: 0.6265104413032532 Training accuracy = 0.8999999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [18/500], Loss: 0.6243404150009155 Training accuracy = 0.8999999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [19/500], Loss: 0.6220884323120117 Training accuracy = 0.8999999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [20/500], Loss: 0.6189721822738647 Training accuracy = 0.9125000238418579 | Test accuracy = 0.8999999761581421\n",
      "Epoch [21/500], Loss: 0.6148843169212341 Training accuracy = 0.9125000238418579 | Test accuracy = 0.8999999761581421\n",
      "Epoch [22/500], Loss: 0.6103123426437378 Training accuracy = 0.9125000238418579 | Test accuracy = 0.8500000238418579\n",
      "Epoch [23/500], Loss: 0.6059332489967346 Training accuracy = 0.800000011920929 | Test accuracy = 0.800000011920929\n",
      "Epoch [24/500], Loss: 0.6021888852119446 Training accuracy = 0.7875000238418579 | Test accuracy = 0.8500000238418579\n",
      "Epoch [25/500], Loss: 0.59907066822052 Training accuracy = 0.737500011920929 | Test accuracy = 0.8500000238418579\n",
      "Epoch [26/500], Loss: 0.5962017774581909 Training accuracy = 0.737500011920929 | Test accuracy = 0.8500000238418579\n",
      "Epoch [27/500], Loss: 0.5931299924850464 Training accuracy = 0.75 | Test accuracy = 0.8500000238418579\n",
      "Epoch [28/500], Loss: 0.5896186828613281 Training accuracy = 0.800000011920929 | Test accuracy = 0.8500000238418579\n",
      "Epoch [29/500], Loss: 0.5857539176940918 Training accuracy = 0.8125 | Test accuracy = 0.8500000238418579\n",
      "Epoch [30/500], Loss: 0.5818355679512024 Training accuracy = 0.8374999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [31/500], Loss: 0.5781580209732056 Training accuracy = 0.9125000238418579 | Test accuracy = 0.8500000238418579\n",
      "Epoch [32/500], Loss: 0.5748276710510254 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [33/500], Loss: 0.5717231035232544 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [34/500], Loss: 0.5686079859733582 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [35/500], Loss: 0.5653046369552612 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [36/500], Loss: 0.561802089214325 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [37/500], Loss: 0.5582355856895447 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [38/500], Loss: 0.5547724962234497 Training accuracy = 0.9125000238418579 | Test accuracy = 0.8500000238418579\n",
      "Epoch [39/500], Loss: 0.5514956712722778 Training accuracy = 0.9125000238418579 | Test accuracy = 0.8500000238418579\n",
      "Epoch [40/500], Loss: 0.5483632683753967 Training accuracy = 0.9125000238418579 | Test accuracy = 0.8500000238418579\n",
      "Epoch [41/500], Loss: 0.5452584624290466 Training accuracy = 0.9125000238418579 | Test accuracy = 0.8500000238418579\n",
      "Epoch [42/500], Loss: 0.5420829057693481 Training accuracy = 0.9125000238418579 | Test accuracy = 0.8500000238418579\n",
      "Epoch [43/500], Loss: 0.538821280002594 Training accuracy = 0.925000011920929 | Test accuracy = 0.8500000238418579\n",
      "Epoch [44/500], Loss: 0.5355385541915894 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [45/500], Loss: 0.5323212742805481 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [46/500], Loss: 0.529213547706604 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [47/500], Loss: 0.526192307472229 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [48/500], Loss: 0.5231947898864746 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [49/500], Loss: 0.5201703906059265 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [50/500], Loss: 0.5171156525611877 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [51/500], Loss: 0.5140687227249146 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [52/500], Loss: 0.5110747218132019 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [53/500], Loss: 0.5081510543823242 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [54/500], Loss: 0.5052797794342041 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [55/500], Loss: 0.5024275183677673 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [56/500], Loss: 0.4995729327201843 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [57/500], Loss: 0.4967212677001953 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [58/500], Loss: 0.49389544129371643 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [59/500], Loss: 0.49111562967300415 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [60/500], Loss: 0.48838406801223755 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [61/500], Loss: 0.48568621277809143 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [62/500], Loss: 0.4830048680305481 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [63/500], Loss: 0.48033374547958374 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [64/500], Loss: 0.47768062353134155 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [65/500], Loss: 0.4750586152076721 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [66/500], Loss: 0.47247472405433655 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [67/500], Loss: 0.46992555260658264 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [68/500], Loss: 0.4674016535282135 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [69/500], Loss: 0.46489620208740234 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [70/500], Loss: 0.4624098241329193 Training accuracy = 0.9375 | Test accuracy = 0.8999999761581421\n",
      "Epoch [71/500], Loss: 0.4599488377571106 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [72/500], Loss: 0.4575185775756836 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [73/500], Loss: 0.4551193118095398 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [74/500], Loss: 0.45274677872657776 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [75/500], Loss: 0.4503958821296692 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [76/500], Loss: 0.4480651915073395 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [77/500], Loss: 0.44575709104537964 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [78/500], Loss: 0.4434750974178314 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [79/500], Loss: 0.44122037291526794 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [80/500], Loss: 0.4389913082122803 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [81/500], Loss: 0.43678492307662964 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [82/500], Loss: 0.43459969758987427 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [83/500], Loss: 0.43243616819381714 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [84/500], Loss: 0.43029603362083435 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [85/500], Loss: 0.4281802773475647 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [86/500], Loss: 0.4260881543159485 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [87/500], Loss: 0.424017995595932 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [88/500], Loss: 0.4219684600830078 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [89/500], Loss: 0.4199395179748535 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [90/500], Loss: 0.4179319441318512 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [91/500], Loss: 0.4159463047981262 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [92/500], Loss: 0.4139823317527771 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [93/500], Loss: 0.41203922033309937 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [94/500], Loss: 0.41011595726013184 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [95/500], Loss: 0.40821224451065063 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [96/500], Loss: 0.4063284397125244 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [97/500], Loss: 0.4044646620750427 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [98/500], Loss: 0.4026208519935608 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [99/500], Loss: 0.40079623460769653 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [100/500], Loss: 0.39899033308029175 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [101/500], Loss: 0.397202730178833 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [102/500], Loss: 0.3954335153102875 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [103/500], Loss: 0.39368265867233276 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [104/500], Loss: 0.3919500708580017 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [105/500], Loss: 0.3902353346347809 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [106/500], Loss: 0.38853809237480164 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [107/500], Loss: 0.38685792684555054 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [108/500], Loss: 0.3851948082447052 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [109/500], Loss: 0.38354864716529846 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [110/500], Loss: 0.381919264793396 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [111/500], Loss: 0.3803063929080963 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [112/500], Loss: 0.378709614276886 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [113/500], Loss: 0.3771287202835083 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [114/500], Loss: 0.3755635619163513 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [115/500], Loss: 0.3740139603614807 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [116/500], Loss: 0.3724798858165741 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [117/500], Loss: 0.37096095085144043 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [118/500], Loss: 0.3694569766521454 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [119/500], Loss: 0.36796772480010986 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [120/500], Loss: 0.36649301648139954 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [121/500], Loss: 0.36503273248672485 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [122/500], Loss: 0.3635866045951843 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [123/500], Loss: 0.3621545135974884 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [124/500], Loss: 0.360736221075058 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [125/500], Loss: 0.35933154821395874 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [126/500], Loss: 0.3579402565956116 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [127/500], Loss: 0.35656222701072693 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [128/500], Loss: 0.35519731044769287 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [129/500], Loss: 0.3538453280925751 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [130/500], Loss: 0.3525061011314392 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [131/500], Loss: 0.3511793613433838 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [132/500], Loss: 0.3498651087284088 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [133/500], Loss: 0.3485630452632904 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [134/500], Loss: 0.347273051738739 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [135/500], Loss: 0.3459950387477875 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [136/500], Loss: 0.3447287678718567 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [137/500], Loss: 0.3434740900993347 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [138/500], Loss: 0.3422308564186096 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [139/500], Loss: 0.34099894762039185 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [140/500], Loss: 0.3397781252861023 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [141/500], Loss: 0.33856838941574097 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [142/500], Loss: 0.33736947178840637 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [143/500], Loss: 0.33618131279945374 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [144/500], Loss: 0.33500373363494873 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [145/500], Loss: 0.3338366150856018 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [146/500], Loss: 0.33267977833747864 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [147/500], Loss: 0.3315331041812897 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [148/500], Loss: 0.33039653301239014 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [149/500], Loss: 0.3292698264122009 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [150/500], Loss: 0.3281528949737549 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [151/500], Loss: 0.32704561948776245 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [152/500], Loss: 0.32594794034957886 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [153/500], Loss: 0.3248596489429474 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [154/500], Loss: 0.32378068566322327 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [155/500], Loss: 0.32271087169647217 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [156/500], Loss: 0.3216501474380493 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [157/500], Loss: 0.3205983340740204 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [158/500], Loss: 0.3195553719997406 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [159/500], Loss: 0.3185211420059204 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [160/500], Loss: 0.31749555468559265 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [161/500], Loss: 0.316478431224823 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [162/500], Loss: 0.31546974182128906 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [163/500], Loss: 0.3144693076610565 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [164/500], Loss: 0.313477098941803 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [165/500], Loss: 0.3124929964542389 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [166/500], Loss: 0.3115168511867523 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [167/500], Loss: 0.3105486035346985 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [168/500], Loss: 0.309588223695755 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [169/500], Loss: 0.30863550305366516 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [170/500], Loss: 0.3076903223991394 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [171/500], Loss: 0.3067527711391449 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [172/500], Loss: 0.30582258105278015 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [173/500], Loss: 0.30489975214004517 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [174/500], Loss: 0.3039841651916504 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [175/500], Loss: 0.30307573080062866 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [176/500], Loss: 0.3021743893623352 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [177/500], Loss: 0.30128005146980286 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [178/500], Loss: 0.30039259791374207 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [179/500], Loss: 0.29951196908950806 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [180/500], Loss: 0.29863810539245605 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [181/500], Loss: 0.2977708876132965 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [182/500], Loss: 0.29691028594970703 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [183/500], Loss: 0.29605618119239807 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [184/500], Loss: 0.29520848393440247 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [185/500], Loss: 0.2943671643733978 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [186/500], Loss: 0.2935321629047394 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [187/500], Loss: 0.2927033305168152 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [188/500], Loss: 0.29188069701194763 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [189/500], Loss: 0.2910640835762024 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [190/500], Loss: 0.2902534604072571 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [191/500], Loss: 0.2894488275051117 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [192/500], Loss: 0.2886500656604767 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [193/500], Loss: 0.2878570556640625 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [194/500], Loss: 0.28706979751586914 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [195/500], Loss: 0.2862882614135742 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [196/500], Loss: 0.2855122685432434 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [197/500], Loss: 0.2847418189048767 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [198/500], Loss: 0.28397688269615173 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [199/500], Loss: 0.2832173705101013 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [200/500], Loss: 0.2824632227420807 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [201/500], Loss: 0.2817143499851227 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [202/500], Loss: 0.2809707224369049 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [203/500], Loss: 0.28023234009742737 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [204/500], Loss: 0.2794990539550781 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [205/500], Loss: 0.2787708044052124 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [206/500], Loss: 0.2780476212501526 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [207/500], Loss: 0.2773294150829315 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [208/500], Loss: 0.27661603689193726 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [209/500], Loss: 0.2759076654911041 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [210/500], Loss: 0.2752039432525635 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [211/500], Loss: 0.2745051383972168 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [212/500], Loss: 0.2738109230995178 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [213/500], Loss: 0.2731214165687561 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [214/500], Loss: 0.2724364399909973 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [215/500], Loss: 0.271756112575531 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [216/500], Loss: 0.27108028531074524 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [217/500], Loss: 0.27040886878967285 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [218/500], Loss: 0.269741952419281 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [219/500], Loss: 0.2690793573856354 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [220/500], Loss: 0.2684210538864136 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [221/500], Loss: 0.267767071723938 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [222/500], Loss: 0.26711732149124146 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [223/500], Loss: 0.266471803188324 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [224/500], Loss: 0.265830397605896 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [225/500], Loss: 0.2651931643486023 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [226/500], Loss: 0.26455992460250854 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [227/500], Loss: 0.26393070816993713 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [228/500], Loss: 0.2633054852485657 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [229/500], Loss: 0.26268428564071655 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [230/500], Loss: 0.26206693053245544 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [231/500], Loss: 0.26145344972610474 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [232/500], Loss: 0.26084378361701965 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [233/500], Loss: 0.26023799180984497 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [234/500], Loss: 0.259635865688324 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [235/500], Loss: 0.25903746485710144 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [236/500], Loss: 0.25844281911849976 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [237/500], Loss: 0.2578517496585846 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [238/500], Loss: 0.25726428627967834 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [239/500], Loss: 0.256680428981781 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [240/500], Loss: 0.2561001479625702 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [241/500], Loss: 0.25552329421043396 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [242/500], Loss: 0.25494998693466187 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [243/500], Loss: 0.2543800473213196 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [244/500], Loss: 0.25381356477737427 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [245/500], Loss: 0.25325047969818115 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [246/500], Loss: 0.2526906728744507 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [247/500], Loss: 0.2521342635154724 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [248/500], Loss: 0.2515811026096344 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [249/500], Loss: 0.25103121995925903 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [250/500], Loss: 0.2504844069480896 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [251/500], Loss: 0.2499409168958664 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [252/500], Loss: 0.24940058588981628 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [253/500], Loss: 0.2488633692264557 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [254/500], Loss: 0.24832923710346222 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [255/500], Loss: 0.2477981597185135 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [256/500], Loss: 0.2472701519727707 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [257/500], Loss: 0.24674519896507263 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [258/500], Loss: 0.24622316658496857 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [259/500], Loss: 0.24570414423942566 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [260/500], Loss: 0.24518804252147675 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [261/500], Loss: 0.24467483162879944 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [262/500], Loss: 0.2441645860671997 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [263/500], Loss: 0.24365708231925964 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [264/500], Loss: 0.24315249919891357 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [265/500], Loss: 0.24265065789222717 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [266/500], Loss: 0.24215169250965118 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [267/500], Loss: 0.2416553944349289 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [268/500], Loss: 0.24116186797618866 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [269/500], Loss: 0.2406710684299469 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [270/500], Loss: 0.24018292129039764 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [271/500], Loss: 0.23969745635986328 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [272/500], Loss: 0.23921462893486023 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [273/500], Loss: 0.2387344390153885 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [274/500], Loss: 0.23825684189796448 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [275/500], Loss: 0.23778173327445984 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [276/500], Loss: 0.2373092621564865 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [277/500], Loss: 0.23683933913707733 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [278/500], Loss: 0.23637184500694275 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [279/500], Loss: 0.23590686917304993 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [280/500], Loss: 0.2354443371295929 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [281/500], Loss: 0.23498424887657166 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [282/500], Loss: 0.2345266342163086 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [283/500], Loss: 0.23407141864299774 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [284/500], Loss: 0.23361854255199432 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [285/500], Loss: 0.23316800594329834 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [286/500], Loss: 0.23271985352039337 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [287/500], Loss: 0.23227402567863464 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [288/500], Loss: 0.23183050751686096 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [289/500], Loss: 0.23138928413391113 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [290/500], Loss: 0.23095031082630157 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [291/500], Loss: 0.2305135428905487 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [292/500], Loss: 0.23007908463478088 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [293/500], Loss: 0.22964675724506378 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [294/500], Loss: 0.22921665012836456 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [295/500], Loss: 0.22878876328468323 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [296/500], Loss: 0.22836296260356903 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [297/500], Loss: 0.22793933749198914 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [298/500], Loss: 0.22751784324645996 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [299/500], Loss: 0.22709843516349792 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [300/500], Loss: 0.2266811579465866 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [301/500], Loss: 0.22626593708992004 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [302/500], Loss: 0.22585275769233704 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [303/500], Loss: 0.22544161975383759 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [304/500], Loss: 0.2250324934720993 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [305/500], Loss: 0.22462542355060577 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [306/500], Loss: 0.22422032058238983 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [307/500], Loss: 0.22381719946861267 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [308/500], Loss: 0.2234160602092743 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [309/500], Loss: 0.22301681339740753 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [310/500], Loss: 0.22261953353881836 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [311/500], Loss: 0.2222241908311844 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [312/500], Loss: 0.22183065116405487 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [313/500], Loss: 0.22143912315368652 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [314/500], Loss: 0.22104939818382263 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [315/500], Loss: 0.22066159546375275 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [316/500], Loss: 0.22027559578418732 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [317/500], Loss: 0.21989142894744873 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [318/500], Loss: 0.2195090800523758 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [319/500], Loss: 0.21912851929664612 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [320/500], Loss: 0.2187497615814209 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [321/500], Loss: 0.21837277710437775 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [322/500], Loss: 0.21799758076667786 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [323/500], Loss: 0.21762411296367645 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [324/500], Loss: 0.21725234389305115 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [325/500], Loss: 0.2168823927640915 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [326/500], Loss: 0.21651411056518555 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [327/500], Loss: 0.2161475121974945 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [328/500], Loss: 0.21578261256217957 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [329/500], Loss: 0.21541938185691833 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [330/500], Loss: 0.21505782008171082 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [331/500], Loss: 0.21469788253307343 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [332/500], Loss: 0.21433958411216736 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [333/500], Loss: 0.2139829844236374 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [334/500], Loss: 0.2136279046535492 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [335/500], Loss: 0.21327447891235352 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [336/500], Loss: 0.212922602891922 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [337/500], Loss: 0.212572380900383 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [338/500], Loss: 0.21222367882728577 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [339/500], Loss: 0.2118765413761139 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [340/500], Loss: 0.21153099834918976 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [341/500], Loss: 0.21118691563606262 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [342/500], Loss: 0.21084432303905487 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [343/500], Loss: 0.21050336956977844 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [344/500], Loss: 0.21016383171081543 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [345/500], Loss: 0.20982582867145538 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [346/500], Loss: 0.20948925614356995 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [347/500], Loss: 0.2091541588306427 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [348/500], Loss: 0.20882058143615723 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [349/500], Loss: 0.20848841965198517 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [350/500], Loss: 0.2081577479839325 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [351/500], Loss: 0.20782847702503204 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [352/500], Loss: 0.2075006067752838 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [353/500], Loss: 0.207174152135849 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [354/500], Loss: 0.20684914290905 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [355/500], Loss: 0.206525519490242 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [356/500], Loss: 0.20620322227478027 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [357/500], Loss: 0.20588234066963196 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [358/500], Loss: 0.20556282997131348 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [359/500], Loss: 0.20524466037750244 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [360/500], Loss: 0.20492784678936005 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [361/500], Loss: 0.2046123445034027 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [362/500], Loss: 0.2042982131242752 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [363/500], Loss: 0.20398536324501038 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [364/500], Loss: 0.20367386937141418 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [365/500], Loss: 0.20336365699768066 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [366/500], Loss: 0.203054741024971 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [367/500], Loss: 0.20274707674980164 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [368/500], Loss: 0.20244073867797852 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [369/500], Loss: 0.20213571190834045 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [370/500], Loss: 0.20183181762695312 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [371/500], Loss: 0.20152921974658966 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [372/500], Loss: 0.20122790336608887 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [373/500], Loss: 0.20092782378196716 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [374/500], Loss: 0.20062895119190216 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [375/500], Loss: 0.20033128559589386 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [376/500], Loss: 0.20003488659858704 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [377/500], Loss: 0.19973963499069214 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [378/500], Loss: 0.19944557547569275 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [379/500], Loss: 0.19915273785591125 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [380/500], Loss: 0.19886109232902527 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [381/500], Loss: 0.19857056438922882 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [382/500], Loss: 0.1982811987400055 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [383/500], Loss: 0.19799309968948364 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [384/500], Loss: 0.19770610332489014 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [385/500], Loss: 0.19742023944854736 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [386/500], Loss: 0.19713549315929413 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [387/500], Loss: 0.196851909160614 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [388/500], Loss: 0.19656941294670105 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [389/500], Loss: 0.1962880641222 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [390/500], Loss: 0.19600780308246613 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [391/500], Loss: 0.19572865962982178 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [392/500], Loss: 0.19545061886310577 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [393/500], Loss: 0.1951736956834793 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [394/500], Loss: 0.19489780068397522 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [395/500], Loss: 0.1946229636669159 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [396/500], Loss: 0.19434919953346252 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [397/500], Loss: 0.19407658278942108 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [398/500], Loss: 0.19380494952201843 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [399/500], Loss: 0.19353438913822174 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [400/500], Loss: 0.19326487183570862 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [401/500], Loss: 0.19299635291099548 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [402/500], Loss: 0.1927289515733719 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [403/500], Loss: 0.1924624741077423 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [404/500], Loss: 0.1921970546245575 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [405/500], Loss: 0.19193267822265625 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [406/500], Loss: 0.1916692554950714 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [407/500], Loss: 0.19140687584877014 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [408/500], Loss: 0.19114546477794647 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [409/500], Loss: 0.1908850371837616 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [410/500], Loss: 0.1906256377696991 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [411/500], Loss: 0.19036714732646942 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [412/500], Loss: 0.19010968506336212 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [413/500], Loss: 0.18985316157341003 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [414/500], Loss: 0.18959760665893555 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [415/500], Loss: 0.18934300541877747 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [416/500], Loss: 0.18908937275409698 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [417/500], Loss: 0.18883660435676575 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [418/500], Loss: 0.1885848492383957 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [419/500], Loss: 0.18833401799201965 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [420/500], Loss: 0.18808409571647644 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [421/500], Loss: 0.18783509731292725 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [422/500], Loss: 0.18758703768253326 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [423/500], Loss: 0.18733984231948853 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [424/500], Loss: 0.18709363043308258 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [425/500], Loss: 0.18684819340705872 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [426/500], Loss: 0.18660375475883484 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [427/500], Loss: 0.186360165476799 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [428/500], Loss: 0.186117485165596 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [429/500], Loss: 0.18587565422058105 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [430/500], Loss: 0.18563470244407654 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [431/500], Loss: 0.18539461493492126 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [432/500], Loss: 0.18515543639659882 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [433/500], Loss: 0.18491710722446442 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [434/500], Loss: 0.18467959761619568 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [435/500], Loss: 0.18444296717643738 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [436/500], Loss: 0.18420715630054474 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [437/500], Loss: 0.18397222459316254 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [438/500], Loss: 0.183738112449646 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [439/500], Loss: 0.1835048496723175 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [440/500], Loss: 0.1832723617553711 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [441/500], Loss: 0.1830407679080963 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [442/500], Loss: 0.18280991911888123 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [443/500], Loss: 0.182579904794693 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [444/500], Loss: 0.18235072493553162 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [445/500], Loss: 0.1821223497390747 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [446/500], Loss: 0.1818947046995163 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [447/500], Loss: 0.18166793882846832 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [448/500], Loss: 0.18144193291664124 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [449/500], Loss: 0.181216761469841 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [450/500], Loss: 0.18099233508110046 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [451/500], Loss: 0.1807686686515808 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [452/500], Loss: 0.18054576218128204 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [453/500], Loss: 0.18032369017601013 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [454/500], Loss: 0.18010231852531433 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [455/500], Loss: 0.17988178133964539 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [456/500], Loss: 0.17966194450855255 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [457/500], Loss: 0.179442897439003 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [458/500], Loss: 0.17922458052635193 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [459/500], Loss: 0.17900702357292175 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [460/500], Loss: 0.1787901669740677 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [461/500], Loss: 0.17857405543327332 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [462/500], Loss: 0.17835870385169983 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [463/500], Loss: 0.17814409732818604 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [464/500], Loss: 0.17793017625808716 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [465/500], Loss: 0.17771701514720917 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [466/500], Loss: 0.1775045543909073 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [467/500], Loss: 0.1772928237915039 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [468/500], Loss: 0.17708180844783783 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [469/500], Loss: 0.17687146365642548 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [470/500], Loss: 0.17666184902191162 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [471/500], Loss: 0.17645294964313507 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [472/500], Loss: 0.17624470591545105 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [473/500], Loss: 0.17603716254234314 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [474/500], Loss: 0.17583033442497253 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [475/500], Loss: 0.17562417685985565 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [476/500], Loss: 0.17541876435279846 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [477/500], Loss: 0.17521393299102783 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [478/500], Loss: 0.1750098168849945 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [479/500], Loss: 0.1748063713312149 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [480/500], Loss: 0.17460358142852783 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [481/500], Loss: 0.17440149188041687 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [482/500], Loss: 0.17420005798339844 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [483/500], Loss: 0.17399926483631134 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [484/500], Loss: 0.17379917204380035 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [485/500], Loss: 0.17359964549541473 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [486/500], Loss: 0.1734008491039276 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [487/500], Loss: 0.17320264875888824 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [488/500], Loss: 0.1730050891637802 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [489/500], Loss: 0.1728082001209259 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [490/500], Loss: 0.17261192202568054 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [491/500], Loss: 0.1724162995815277 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [492/500], Loss: 0.17222130298614502 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [493/500], Loss: 0.17202690243721008 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [494/500], Loss: 0.17183318734169006 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [495/500], Loss: 0.1716400384902954 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [496/500], Loss: 0.1714475452899933 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [497/500], Loss: 0.17125561833381653 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [498/500], Loss: 0.17106430232524872 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [499/500], Loss: 0.17087364196777344 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [500/500], Loss: 0.1706835776567459 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# rf.fit(train, labels_train)\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.05\n",
    "num_epochs = 500\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "train = train.float()\n",
    "test = test.float()\n",
    "labels_train = labels_train.float()\n",
    "labels_test = labels_test.float()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model.forward(train)\n",
    "    loss = loss_fn(outputs, labels_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Calculate training and validation accuracy every epoch\n",
    "    training_accuracy = 0\n",
    "    test_accuracy = 0\n",
    "     \n",
    "    model.eval()\n",
    "    outputs = model.predict(train)\n",
    "    training_accuracy = (outputs == labels_train).float().mean()\n",
    "    outputs = model.predict(test)\n",
    "    test_accuracy = (outputs == labels_test).float().mean()\n",
    "    #print('Training accuracy = {} | Test accuracy = {}'.format(training_accuracy, test_accuracy))\n",
    "    \n",
    "    # Print the loss every epoch\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}' + ' Training accuracy = {} | Test accuracy = {}'.format(training_accuracy, test_accuracy))\n",
    "        \n",
    "print('Done!')\n",
    "\n",
    "\n",
    "# n_samples = test.shape[1]\n",
    "\n",
    "# predictions = np.zeros((n_samples,1))\n",
    "# for i in range(n_samples):\n",
    "#     with torch.no_grad():\n",
    "#         predictions[i] = model.predict(train[i]).detach().numpy()\n",
    "\n",
    "# labels_test = labels_test.numpy().astype(int)\n",
    "\n",
    "# correct_predictions = 0\n",
    "# incorrect_predictions = 0\n",
    "# for i in range(n_samples):\n",
    "#     if predictions[i] == labels_test[i]:\n",
    "#         correct_predictions = correct_predictions + 1\n",
    "#     else:\n",
    "#         incorrect_predictions = incorrect_predictions + 1\n",
    "\n",
    "# accuracy = correct_predictions/n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn.metrics.accuracy_score(labels_test, rf.predict(test))\n",
    "\n",
    "sklearn.metrics.accuracy_score(labels_test, model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  label\n",
       "0        6.1        1.9    0.0\n",
       "1        5.6        1.4    0.0\n",
       "2        5.1        1.6    1.0\n",
       "3        6.4        2.0    0.0\n",
       "4        5.9        2.3    0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe with feature and label data\n",
    "test_array = test.numpy()\n",
    "labels_array = labels_test.numpy()\n",
    "stacked_array = np.hstack((test_array, labels_array.reshape(-1, 1)))\n",
    "feature_columns = [f'feature_{i}' for i in range(test_array.shape[1])]\n",
    "column_names = feature_columns + ['label']\n",
    "\n",
    "# Create DataFrame\n",
    "test_df = pd.DataFrame(stacked_array, columns=column_names)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap PyTorch model using dice_ml\n",
    "from dice_ml.model_interfaces.pytorch_model import PyTorchModel\n",
    "wrapped_model = PyTorchModel(model=LogisticRegressor(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_df.drop('label',axis=1)\n",
    "\n",
    "d = dice_ml.Data(dataframe=test_df, continuous_features=['feature_0', 'feature_1'], outcome_name='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Dice object\n",
    "# from dice_ml import Dice\n",
    "# dice = Dice(wrapped_model)\n",
    "\n",
    "# Using sklearn backend\n",
    "m = dice_ml.Model(model=model, backend=\"PYT\")\n",
    "# Using method=random for generating CFs\n",
    "exp = dice_ml.Dice(d, m, method=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m i_explained \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m e1 \u001b[38;5;241m=\u001b[39m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_counterfactuals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi_explained\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi_explained\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_CFs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopposite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m e1\u001b[38;5;241m.\u001b[39mvisualize_as_dataframe(show_only_changes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/desktop/AMLvenv/EXPLORERvenv/lib/python3.10/site-packages/dice_ml/explainer_interfaces/explainer_base.py:186\u001b[0m, in \u001b[0;36mExplainerBase.generate_counterfactuals\u001b[0;34m(self, query_instances, total_CFs, desired_class, desired_range, permitted_range, features_to_vary, stopping_threshold, posthoc_sparsity_param, proximity_weight, sparsity_weight, diversity_weight, categorical_penalty, posthoc_sparsity_algorithm, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query_instance \u001b[38;5;129;01min\u001b[39;00m tqdm(query_instances_list):\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_interface\u001b[38;5;241m.\u001b[39mset_continuous_feature_indexes(query_instance)\n\u001b[0;32m--> 186\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_counterfactuals\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_CFs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesired_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesired_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesired_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesired_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpermitted_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpermitted_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures_to_vary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures_to_vary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposthoc_sparsity_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposthoc_sparsity_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposthoc_sparsity_algorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposthoc_sparsity_algorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     res\u001b[38;5;241m.\u001b[39mtest_instance_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_interface\u001b[38;5;241m.\u001b[39mensure_consistent_type(\n\u001b[1;32m    198\u001b[0m             res\u001b[38;5;241m.\u001b[39mtest_instance_df, query_instance)\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mfinal_cfs_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mfinal_cfs_df) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/desktop/AMLvenv/EXPLORERvenv/lib/python3.10/site-packages/dice_ml/explainer_interfaces/dice_genetic.py:280\u001b[0m, in \u001b[0;36mDiceGenetic._generate_counterfactuals\u001b[0;34m(self, query_instance, total_CFs, initialization, desired_range, desired_class, proximity_weight, sparsity_weight, diversity_weight, categorical_penalty, algorithm, features_to_vary, permitted_range, yloss_type, diversity_loss_type, feature_weights, stopping_threshold, posthoc_sparsity_param, posthoc_sparsity_algorithm, maxiterations, thresh, verbose)\u001b[0m\n\u001b[1;32m    277\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_fn_scores(query_instance)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_pred \u001b[38;5;241m=\u001b[39m test_pred\n\u001b[0;32m--> 280\u001b[0m desired_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmisc_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m query_instance_df_dummies \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(query_instance_orig)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_interface\u001b[38;5;241m.\u001b[39mget_all_dummy_colnames():\n",
      "File \u001b[0;32m~/desktop/AMLvenv/EXPLORERvenv/lib/python3.10/site-packages/dice_ml/explainer_interfaces/explainer_base.py:672\u001b[0m, in \u001b[0;36mExplainerBase.misc_init\u001b[0;34m(self, stopping_threshold, desired_class, desired_range, test_pred)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopping_threshold \u001b[38;5;241m=\u001b[39m stopping_threshold\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m==\u001b[39m ModelTypes\u001b[38;5;241m.\u001b[39mClassifier:\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_cf_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m--> 672\u001b[0m         [[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_target_cfs_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesired_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_output_nodes\u001b[49m\u001b[43m)\u001b[49m]],\n\u001b[1;32m    673\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    674\u001b[0m     desired_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_cf_class[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_cf_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopping_threshold \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n",
      "File \u001b[0;32m~/desktop/AMLvenv/EXPLORERvenv/lib/python3.10/site-packages/dice_ml/explainer_interfaces/explainer_base.py:703\u001b[0m, in \u001b[0;36mExplainerBase.infer_target_cfs_class\u001b[0;34m(self, desired_class_input, original_pred, num_output_nodes)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m num_output_nodes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# only for pytorch DL model\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     original_pred_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(original_pred)\n\u001b[0;32m--> 703\u001b[0m     target_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43moriginal_pred_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m target_class\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m num_output_nodes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "i_explained = 0\n",
    "\n",
    "e1 = exp.generate_counterfactuals(x_test[i_explained:i_explained+1], total_CFs=5, desired_class=\"opposite\")\n",
    "e1.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_0  feature_1  label\n",
      "0        6.1        1.4      1\n",
      "1        4.5        1.4      1\n",
      "2        6.1        1.2      1\n",
      "3        3.7        1.5      1\n",
      "4        6.4        1.5      1\n",
      "[[6.0999999  1.39999998]\n",
      " [4.5        1.39999998]\n",
      " [6.0999999  1.20000005]\n",
      " [3.70000005 1.5       ]\n",
      " [6.4000001  1.5       ]]\n",
      "[6.0999999  1.39999998]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coefficients = model.linear.weight.detach().numpy()\n",
    "biases = model.linear.bias.detach().numpy()\n",
    "decision_boundary = lambda x : (-biases)/coefficients[0][1] - x*coefficients[0][0]/coefficients[0][1]\n",
    "\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = decision_boundary(x)\n",
    "\n",
    "features_test = test.numpy() if not isinstance(test, np.ndarray) else test\n",
    "labels_test = labels_test.numpy() if not isinstance(labels_test, np.ndarray) else labels_test\n",
    "\n",
    "# Plotting the decision boundary and the test set\n",
    "feature_names = iris.feature_names[2:]\n",
    "target_names = iris.target_names[1:][::-1]\n",
    "plt.plot(x, y)\n",
    "ix0 = (labels_test == 0).ravel()\n",
    "ix1 = (labels_test == 1).ravel()\n",
    "plt.scatter(features_test[ix0,0], features_test[ix0, 1], c = 'b', label = target_names[0])\n",
    "plt.scatter(features_test[ix1,0], features_test[ix1, 1], c = 'g', label = target_names[1])\n",
    "point_explained = features_test[i_explained,:]\n",
    "circle = plt.Circle(point_explained, 0.1, color='r', fill=False)\n",
    "plt.gca().add_patch(circle)\n",
    "\n",
    "\n",
    "\n",
    "cfs_df = e1.cf_examples_list[0].final_cfs_df\n",
    "print(cfs_df)\n",
    "cfs_array = cfs_df.drop('label',axis=1).iloc[:].values.astype(float)\n",
    "print(cfs_array)\n",
    "print(cfs_array[0,:])\n",
    "for i in range(cfs_array.shape[0]):\n",
    "    plt.scatter(cfs_array[i,0], cfs_array[i,1], c = 'r', label = 'Counterfactuals')\n",
    "\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0, 10)\n",
    "plt.xlabel(feature_names[0])\n",
    "plt.ylabel(feature_names[1])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXPLORERvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
