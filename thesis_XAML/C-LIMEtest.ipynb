{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import pandas as pd\n",
    "np.random.seed(1)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "iris = sklearn.datasets.load_iris()\n",
    "\n",
    "print(type(iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(features[labels == 0,2], features[labels == 0, 3], c = 'r', label = 'Setosa')\n",
    "plt.scatter(features[labels == 1,2], features[labels == 1, 3], c = 'g', label = 'Versicolor')\n",
    "plt.scatter(features[labels == 2,2], features[labels == 2, 3], c = 'b', label = 'Virginica')\n",
    "plt.show()\n",
    "\n",
    "# # Visualizing only classes green and blue in 3d (in the first three features)\n",
    "# custom_colors = ['g', 'b']\n",
    "# cmap_custom = matplotlib.colors.ListedColormap(custom_colors)\n",
    "# fig = plt.figure(figsize=(10, 8))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(features[labels != 0,1], features[labels != 0,2], features[labels != 0,3], c = labels[labels != 0], cmap = cmap_custom)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving only the green and blue classes with features 2, and 3\n",
    "features = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "features = features[labels != 0] # Drop class 0\n",
    "features = features[:,2:] # Drop features 0 and 1\n",
    "\n",
    "labels = labels[labels != 0] # Drop class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 2)\n",
      "(20, 2)\n",
      "(80, 1)\n",
      "(20, 1)\n",
      "torch.Size([80, 2])\n",
      "torch.Size([20, 2])\n",
      "torch.Size([80, 1])\n",
      "torch.Size([20, 1])\n",
      "tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1]])\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0]])\n"
     ]
    }
   ],
   "source": [
    "train, test, labels_train, labels_test = sklearn.model_selection.train_test_split(features, labels, train_size=0.80)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(labels_train.reshape(-1,1).shape)\n",
    "print(labels_test.reshape(-1,1).shape)\n",
    "\n",
    "train = torch.from_numpy(train)\n",
    "test = torch.from_numpy(test)\n",
    "labels_train = torch.from_numpy(labels_train).reshape(-1,1)\n",
    "labels_test = torch.from_numpy(labels_test).reshape(-1,1)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(labels_train.shape)\n",
    "print(labels_test.shape)\n",
    "\n",
    "labels_train = labels_train.remainder(2) # 'Relabels' class 2 as class 0 --> Now we have classes 0 and 1\n",
    "labels_test = labels_test.remainder(2) # 'Relabels' class 2 as class 0 --> Now we have classes 0 and 1\n",
    "\n",
    "print(labels_train[:5])\n",
    "print(labels_test[:5])\n",
    "\n",
    "# Since we removed one class and on feature we need to\n",
    "# make some manual adjustments to the feature and target names \n",
    "feature_names = iris.feature_names[2:]\n",
    "target_names = iris.target_names[1:][::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "class LogisticRegressor(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressor, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def class_probabilities(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.forward(x)\n",
    "            class_probs = torch.cat((1-x, x), dim = 1)\n",
    "        return class_probs.reshape(-1,2)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.forward(x)\n",
    "            predicted_class = x.detach().round()\n",
    "        return predicted_class.reshape(-1,1)\n",
    "\n",
    "model = LogisticRegressor(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.4920772314071655 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [2/500], Loss: 1.338945984840393 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [3/500], Loss: 1.1945255994796753 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [4/500], Loss: 1.0622446537017822 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [5/500], Loss: 0.9464088678359985 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [6/500], Loss: 0.8519154787063599 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [7/500], Loss: 0.7834013104438782 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [8/500], Loss: 0.7436782121658325 Training accuracy = 0.3375000059604645 | Test accuracy = 0.550000011920929\n",
      "Epoch [9/500], Loss: 0.7318381071090698 Training accuracy = 0.4000000059604645 | Test accuracy = 0.3499999940395355\n",
      "Epoch [10/500], Loss: 0.742216944694519 Training accuracy = 0.5249999761581421 | Test accuracy = 0.4000000059604645\n",
      "Epoch [11/500], Loss: 0.7654954195022583 Training accuracy = 0.5249999761581421 | Test accuracy = 0.4000000059604645\n",
      "Epoch [12/500], Loss: 0.7916761040687561 Training accuracy = 0.5249999761581421 | Test accuracy = 0.4000000059604645\n",
      "Epoch [13/500], Loss: 0.8129661679267883 Training accuracy = 0.5249999761581421 | Test accuracy = 0.4000000059604645\n",
      "Epoch [14/500], Loss: 0.825003445148468 Training accuracy = 0.5249999761581421 | Test accuracy = 0.4000000059604645\n",
      "Epoch [15/500], Loss: 0.826556384563446 Training accuracy = 0.5249999761581421 | Test accuracy = 0.4000000059604645\n",
      "Epoch [16/500], Loss: 0.8186061978340149 Training accuracy = 0.5249999761581421 | Test accuracy = 0.4000000059604645\n",
      "Epoch [17/500], Loss: 0.8034502267837524 Training accuracy = 0.5249999761581421 | Test accuracy = 0.4000000059604645\n",
      "Epoch [18/500], Loss: 0.7840161919593811 Training accuracy = 0.5249999761581421 | Test accuracy = 0.4000000059604645\n",
      "Epoch [19/500], Loss: 0.7633546590805054 Training accuracy = 0.5249999761581421 | Test accuracy = 0.4000000059604645\n",
      "Epoch [20/500], Loss: 0.7442352175712585 Training accuracy = 0.512499988079071 | Test accuracy = 0.4000000059604645\n",
      "Epoch [21/500], Loss: 0.7288061380386353 Training accuracy = 0.23749999701976776 | Test accuracy = 0.20000000298023224\n",
      "Epoch [22/500], Loss: 0.718335747718811 Training accuracy = 0.36250001192092896 | Test accuracy = 0.550000011920929\n",
      "Epoch [23/500], Loss: 0.7130899429321289 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [24/500], Loss: 0.7123955488204956 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [25/500], Loss: 0.7148929238319397 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [26/500], Loss: 0.7189033627510071 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [27/500], Loss: 0.7228067517280579 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [28/500], Loss: 0.7253316640853882 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [29/500], Loss: 0.7257142663002014 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [30/500], Loss: 0.7237289547920227 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [31/500], Loss: 0.7196226716041565 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [32/500], Loss: 0.7139891982078552 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [33/500], Loss: 0.7076137661933899 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [34/500], Loss: 0.7013112306594849 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [35/500], Loss: 0.6957775354385376 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [36/500], Loss: 0.6914755702018738 Training accuracy = 0.48750001192092896 | Test accuracy = 0.6000000238418579\n",
      "Epoch [37/500], Loss: 0.6885717511177063 Training accuracy = 0.48750001192092896 | Test accuracy = 0.6000000238418579\n",
      "Epoch [38/500], Loss: 0.6869366765022278 Training accuracy = 0.4749999940395355 | Test accuracy = 0.6000000238418579\n",
      "Epoch [39/500], Loss: 0.6862071752548218 Training accuracy = 0.5249999761581421 | Test accuracy = 0.6000000238418579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/500], Loss: 0.6858929991722107 Training accuracy = 0.574999988079071 | Test accuracy = 0.550000011920929\n",
      "Epoch [41/500], Loss: 0.6854991912841797 Training accuracy = 0.6499999761581421 | Test accuracy = 0.6000000238418579\n",
      "Epoch [42/500], Loss: 0.6846330165863037 Training accuracy = 0.6625000238418579 | Test accuracy = 0.6499999761581421\n",
      "Epoch [43/500], Loss: 0.6830731630325317 Training accuracy = 0.675000011920929 | Test accuracy = 0.6499999761581421\n",
      "Epoch [44/500], Loss: 0.6807901263237 Training accuracy = 0.6625000238418579 | Test accuracy = 0.6000000238418579\n",
      "Epoch [45/500], Loss: 0.6779218912124634 Training accuracy = 0.6625000238418579 | Test accuracy = 0.75\n",
      "Epoch [46/500], Loss: 0.6747163534164429 Training accuracy = 0.737500011920929 | Test accuracy = 0.75\n",
      "Epoch [47/500], Loss: 0.6714585423469543 Training accuracy = 0.625 | Test accuracy = 0.75\n",
      "Epoch [48/500], Loss: 0.6684011220932007 Training accuracy = 0.5874999761581421 | Test accuracy = 0.800000011920929\n",
      "Epoch [49/500], Loss: 0.6657119393348694 Training accuracy = 0.550000011920929 | Test accuracy = 0.6499999761581421\n",
      "Epoch [50/500], Loss: 0.6634492874145508 Training accuracy = 0.5375000238418579 | Test accuracy = 0.6499999761581421\n",
      "Epoch [51/500], Loss: 0.6615657210350037 Training accuracy = 0.5249999761581421 | Test accuracy = 0.6000000238418579\n",
      "Epoch [52/500], Loss: 0.6599360108375549 Training accuracy = 0.512499988079071 | Test accuracy = 0.6000000238418579\n",
      "Epoch [53/500], Loss: 0.6583989262580872 Training accuracy = 0.512499988079071 | Test accuracy = 0.6000000238418579\n",
      "Epoch [54/500], Loss: 0.6568008065223694 Training accuracy = 0.512499988079071 | Test accuracy = 0.6000000238418579\n",
      "Epoch [55/500], Loss: 0.6550298929214478 Training accuracy = 0.512499988079071 | Test accuracy = 0.6000000238418579\n",
      "Epoch [56/500], Loss: 0.6530359387397766 Training accuracy = 0.5249999761581421 | Test accuracy = 0.6499999761581421\n",
      "Epoch [57/500], Loss: 0.6508311033248901 Training accuracy = 0.5375000238418579 | Test accuracy = 0.6499999761581421\n",
      "Epoch [58/500], Loss: 0.6484775543212891 Training accuracy = 0.5375000238418579 | Test accuracy = 0.699999988079071\n",
      "Epoch [59/500], Loss: 0.6460638642311096 Training accuracy = 0.550000011920929 | Test accuracy = 0.699999988079071\n",
      "Epoch [60/500], Loss: 0.6436797380447388 Training accuracy = 0.5874999761581421 | Test accuracy = 0.75\n",
      "Epoch [61/500], Loss: 0.6413935422897339 Training accuracy = 0.6499999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [62/500], Loss: 0.6392387747764587 Training accuracy = 0.6875 | Test accuracy = 0.8999999761581421\n",
      "Epoch [63/500], Loss: 0.6372109651565552 Training accuracy = 0.7124999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [64/500], Loss: 0.6352748870849609 Training accuracy = 0.762499988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [65/500], Loss: 0.6333780288696289 Training accuracy = 0.7749999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [66/500], Loss: 0.6314672231674194 Training accuracy = 0.8500000238418579 | Test accuracy = 0.8999999761581421\n",
      "Epoch [67/500], Loss: 0.6295027732849121 Training accuracy = 0.862500011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [68/500], Loss: 0.6274663209915161 Training accuracy = 0.875 | Test accuracy = 0.8999999761581421\n",
      "Epoch [69/500], Loss: 0.6253623366355896 Training accuracy = 0.862500011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [70/500], Loss: 0.6232134699821472 Training accuracy = 0.800000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [71/500], Loss: 0.6210510730743408 Training accuracy = 0.7875000238418579 | Test accuracy = 0.8999999761581421\n",
      "Epoch [72/500], Loss: 0.6189054250717163 Training accuracy = 0.7749999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [73/500], Loss: 0.6167975664138794 Training accuracy = 0.7749999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [74/500], Loss: 0.6147357225418091 Training accuracy = 0.75 | Test accuracy = 0.8999999761581421\n",
      "Epoch [75/500], Loss: 0.6127145290374756 Training accuracy = 0.737500011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [76/500], Loss: 0.6107193231582642 Training accuracy = 0.737500011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [77/500], Loss: 0.608731746673584 Training accuracy = 0.737500011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [78/500], Loss: 0.6067355275154114 Training accuracy = 0.75 | Test accuracy = 0.8999999761581421\n",
      "Epoch [79/500], Loss: 0.6047205924987793 Training accuracy = 0.762499988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [80/500], Loss: 0.6026850342750549 Training accuracy = 0.800000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [81/500], Loss: 0.6006342172622681 Training accuracy = 0.800000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [82/500], Loss: 0.5985779762268066 Training accuracy = 0.800000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [83/500], Loss: 0.5965273380279541 Training accuracy = 0.8125 | Test accuracy = 0.8999999761581421\n",
      "Epoch [84/500], Loss: 0.5944908261299133 Training accuracy = 0.8125 | Test accuracy = 0.8999999761581421\n",
      "Epoch [85/500], Loss: 0.5924728512763977 Training accuracy = 0.8999999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [86/500], Loss: 0.5904728174209595 Training accuracy = 0.9125000238418579 | Test accuracy = 0.8999999761581421\n",
      "Epoch [87/500], Loss: 0.58848637342453 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [88/500], Loss: 0.5865074396133423 Training accuracy = 0.925000011920929 | Test accuracy = 0.8999999761581421\n",
      "Epoch [89/500], Loss: 0.5845300555229187 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [90/500], Loss: 0.5825504064559937 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [91/500], Loss: 0.5805676579475403 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [92/500], Loss: 0.5785835385322571 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [93/500], Loss: 0.5766014456748962 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [94/500], Loss: 0.574625551700592 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [95/500], Loss: 0.5726587176322937 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [96/500], Loss: 0.5707026124000549 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [97/500], Loss: 0.5687569379806519 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [98/500], Loss: 0.5668202042579651 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [99/500], Loss: 0.5648903250694275 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [100/500], Loss: 0.5629653930664062 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [101/500], Loss: 0.5610442757606506 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [102/500], Loss: 0.5591268539428711 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [103/500], Loss: 0.5572141408920288 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [104/500], Loss: 0.5553074479103088 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [105/500], Loss: 0.5534080266952515 Training accuracy = 0.925000011920929 | Test accuracy = 0.949999988079071\n",
      "Epoch [106/500], Loss: 0.551517128944397 Training accuracy = 0.949999988079071 | Test accuracy = 0.949999988079071\n",
      "Epoch [107/500], Loss: 0.5496348142623901 Training accuracy = 0.9624999761581421 | Test accuracy = 0.949999988079071\n",
      "Epoch [108/500], Loss: 0.5477609634399414 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [109/500], Loss: 0.545894980430603 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [110/500], Loss: 0.5440360903739929 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [111/500], Loss: 0.5421838760375977 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [112/500], Loss: 0.5403379797935486 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [113/500], Loss: 0.53849858045578 Training accuracy = 0.949999988079071 | Test accuracy = 0.8500000238418579\n",
      "Epoch [114/500], Loss: 0.5366662740707397 Training accuracy = 0.949999988079071 | Test accuracy = 0.8500000238418579\n",
      "Epoch [115/500], Loss: 0.5348414778709412 Training accuracy = 0.949999988079071 | Test accuracy = 0.8500000238418579\n",
      "Epoch [116/500], Loss: 0.5330246090888977 Training accuracy = 0.949999988079071 | Test accuracy = 0.8500000238418579\n",
      "Epoch [117/500], Loss: 0.5312161445617676 Training accuracy = 0.949999988079071 | Test accuracy = 0.8500000238418579\n",
      "Epoch [118/500], Loss: 0.5294159054756165 Training accuracy = 0.949999988079071 | Test accuracy = 0.8500000238418579\n",
      "Epoch [119/500], Loss: 0.5276238322257996 Training accuracy = 0.949999988079071 | Test accuracy = 0.8500000238418579\n",
      "Epoch [120/500], Loss: 0.525839626789093 Training accuracy = 0.949999988079071 | Test accuracy = 0.8500000238418579\n",
      "Epoch [121/500], Loss: 0.524063229560852 Training accuracy = 0.949999988079071 | Test accuracy = 0.8500000238418579\n",
      "Epoch [122/500], Loss: 0.5222944021224976 Training accuracy = 0.949999988079071 | Test accuracy = 0.8500000238418579\n",
      "Epoch [123/500], Loss: 0.5205332636833191 Training accuracy = 0.949999988079071 | Test accuracy = 0.8500000238418579\n",
      "Epoch [124/500], Loss: 0.5187798142433167 Training accuracy = 0.949999988079071 | Test accuracy = 0.8500000238418579\n",
      "Epoch [125/500], Loss: 0.5170344114303589 Training accuracy = 0.949999988079071 | Test accuracy = 0.8500000238418579\n",
      "Epoch [126/500], Loss: 0.5152972936630249 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [127/500], Loss: 0.5135683417320251 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [128/500], Loss: 0.5118477940559387 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [129/500], Loss: 0.5101355314254761 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [130/500], Loss: 0.5084314942359924 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [131/500], Loss: 0.506735622882843 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [132/500], Loss: 0.5050478577613831 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [133/500], Loss: 0.5033682584762573 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [134/500], Loss: 0.5016967058181763 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [135/500], Loss: 0.5000334978103638 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [136/500], Loss: 0.4983784556388855 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [137/500], Loss: 0.49673181772232056 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [138/500], Loss: 0.49509352445602417 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [139/500], Loss: 0.4934636056423187 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [140/500], Loss: 0.49184203147888184 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [141/500], Loss: 0.49022871255874634 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [142/500], Loss: 0.4886236786842346 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [143/500], Loss: 0.4870268404483795 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [144/500], Loss: 0.48543834686279297 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [145/500], Loss: 0.4838581085205078 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [146/500], Loss: 0.48228615522384644 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [147/500], Loss: 0.480722576379776 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [148/500], Loss: 0.47916722297668457 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [149/500], Loss: 0.47762012481689453 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [150/500], Loss: 0.47608137130737305 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [151/500], Loss: 0.474550724029541 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [152/500], Loss: 0.47302836179733276 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [153/500], Loss: 0.47151416540145874 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [154/500], Loss: 0.4700081944465637 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [155/500], Loss: 0.46851029992103577 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [156/500], Loss: 0.46702060103416443 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [157/500], Loss: 0.46553903818130493 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [158/500], Loss: 0.4640656113624573 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8500000238418579\n",
      "Epoch [159/500], Loss: 0.4626002907752991 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [160/500], Loss: 0.46114295721054077 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [161/500], Loss: 0.4596937596797943 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [162/500], Loss: 0.45825257897377014 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [163/500], Loss: 0.4568193554878235 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [164/500], Loss: 0.45539408922195435 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [165/500], Loss: 0.4539768099784851 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [166/500], Loss: 0.4525674283504486 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [167/500], Loss: 0.45116597414016724 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [168/500], Loss: 0.44977226853370667 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [169/500], Loss: 0.4483864903450012 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [170/500], Loss: 0.44700852036476135 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [171/500], Loss: 0.4456383287906647 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [172/500], Loss: 0.44427576661109924 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [173/500], Loss: 0.4429210126399994 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [174/500], Loss: 0.44157394766807556 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [175/500], Loss: 0.4402344226837158 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [176/500], Loss: 0.4389025568962097 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [177/500], Loss: 0.4375782907009125 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [178/500], Loss: 0.4362615644931793 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [179/500], Loss: 0.43495234847068787 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [180/500], Loss: 0.43365055322647095 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [181/500], Loss: 0.43235620856285095 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [182/500], Loss: 0.4310693144798279 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [183/500], Loss: 0.4297897219657898 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [184/500], Loss: 0.42851749062538147 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [185/500], Loss: 0.4272525906562805 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [186/500], Loss: 0.4259949326515198 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [187/500], Loss: 0.4247444272041321 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [188/500], Loss: 0.4235011041164398 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [189/500], Loss: 0.4222649931907654 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [190/500], Loss: 0.4210359454154968 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [191/500], Loss: 0.41981393098831177 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [192/500], Loss: 0.4185989797115326 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [193/500], Loss: 0.4173911213874817 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [194/500], Loss: 0.4161899983882904 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [195/500], Loss: 0.4149959683418274 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [196/500], Loss: 0.4138087332248688 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [197/500], Loss: 0.4126283526420593 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [198/500], Loss: 0.4114547371864319 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [199/500], Loss: 0.4102879464626312 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [200/500], Loss: 0.409127801656723 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [201/500], Loss: 0.40797439217567444 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [202/500], Loss: 0.4068275988101959 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [203/500], Loss: 0.4056873321533203 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [204/500], Loss: 0.40455371141433716 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [205/500], Loss: 0.40342655777931213 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [206/500], Loss: 0.40230593085289 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [207/500], Loss: 0.40119171142578125 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [208/500], Loss: 0.4000839293003082 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [209/500], Loss: 0.3989824950695038 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [210/500], Loss: 0.39788734912872314 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [211/500], Loss: 0.3967985510826111 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [212/500], Loss: 0.39571595191955566 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [213/500], Loss: 0.3946395516395569 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [214/500], Loss: 0.39356929063796997 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [215/500], Loss: 0.3925052285194397 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [216/500], Loss: 0.3914472460746765 Training accuracy = 0.9624999761581421 | Test accuracy = 0.8999999761581421\n",
      "Epoch [217/500], Loss: 0.39039525389671326 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [218/500], Loss: 0.3893493711948395 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [219/500], Loss: 0.3883093297481537 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [220/500], Loss: 0.3872752785682678 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [221/500], Loss: 0.3862471580505371 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [222/500], Loss: 0.3852248191833496 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [223/500], Loss: 0.3842083215713501 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [224/500], Loss: 0.3831976354122162 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [225/500], Loss: 0.3821926414966583 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [226/500], Loss: 0.3811933696269989 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [227/500], Loss: 0.38019976019859314 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [228/500], Loss: 0.37921175360679626 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [229/500], Loss: 0.3782293498516083 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [230/500], Loss: 0.3772525191307068 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [231/500], Loss: 0.376281201839447 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [232/500], Loss: 0.3753153681755066 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [233/500], Loss: 0.37435489892959595 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [234/500], Loss: 0.37339991331100464 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [235/500], Loss: 0.3724502623081207 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [236/500], Loss: 0.3715059161186218 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [237/500], Loss: 0.37056687474250793 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [238/500], Loss: 0.36963313817977905 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [239/500], Loss: 0.36870452761650085 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [240/500], Loss: 0.36778122186660767 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [241/500], Loss: 0.3668630123138428 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [242/500], Loss: 0.36594992876052856 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [243/500], Loss: 0.3650418817996979 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [244/500], Loss: 0.3641388714313507 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [245/500], Loss: 0.36324092745780945 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [246/500], Loss: 0.36234790086746216 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [247/500], Loss: 0.3614598512649536 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [248/500], Loss: 0.36057668924331665 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [249/500], Loss: 0.3596983850002289 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [250/500], Loss: 0.3588249385356903 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [251/500], Loss: 0.3579562306404114 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [252/500], Loss: 0.35709235072135925 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [253/500], Loss: 0.35623323917388916 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [254/500], Loss: 0.35537877678871155 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [255/500], Loss: 0.3545289635658264 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [256/500], Loss: 0.35368379950523376 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [257/500], Loss: 0.3528432250022888 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [258/500], Loss: 0.35200729966163635 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [259/500], Loss: 0.35117587447166443 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [260/500], Loss: 0.35034888982772827 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [261/500], Loss: 0.34952646493911743 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [262/500], Loss: 0.3487084209918976 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [263/500], Loss: 0.3478948175907135 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [264/500], Loss: 0.347085565328598 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [265/500], Loss: 0.3462807238101959 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [266/500], Loss: 0.34548020362854004 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [267/500], Loss: 0.3446839153766632 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [268/500], Loss: 0.3438919186592102 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [269/500], Loss: 0.34310415387153625 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [270/500], Loss: 0.3423205614089966 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [271/500], Loss: 0.3415411710739136 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [272/500], Loss: 0.34076589345932007 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [273/500], Loss: 0.33999472856521606 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [274/500], Loss: 0.3392276465892792 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [275/500], Loss: 0.3384645879268646 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [276/500], Loss: 0.3377056121826172 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [277/500], Loss: 0.3369506001472473 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [278/500], Loss: 0.3361995816230774 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [279/500], Loss: 0.3354524075984955 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [280/500], Loss: 0.3347092568874359 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [281/500], Loss: 0.33396998047828674 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [282/500], Loss: 0.3332344591617584 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [283/500], Loss: 0.3325028419494629 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [284/500], Loss: 0.3317750096321106 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [285/500], Loss: 0.33105093240737915 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [286/500], Loss: 0.33033066987991333 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [287/500], Loss: 0.3296140730381012 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [288/500], Loss: 0.3289012014865875 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [289/500], Loss: 0.32819199562072754 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [290/500], Loss: 0.3274863362312317 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [291/500], Loss: 0.3267844319343567 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [292/500], Loss: 0.3260860741138458 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [293/500], Loss: 0.3253912031650543 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [294/500], Loss: 0.3246999680995941 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [295/500], Loss: 0.32401221990585327 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [296/500], Loss: 0.3233279585838318 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [297/500], Loss: 0.3226471543312073 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [298/500], Loss: 0.3219698369503021 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [299/500], Loss: 0.32129591703414917 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [300/500], Loss: 0.32062533497810364 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [301/500], Loss: 0.3199581503868103 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [302/500], Loss: 0.31929439306259155 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [303/500], Loss: 0.31863388419151306 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [304/500], Loss: 0.3179767429828644 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [305/500], Loss: 0.3173227608203888 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [306/500], Loss: 0.31667211651802063 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [307/500], Loss: 0.31602469086647034 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [308/500], Loss: 0.31538042426109314 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [309/500], Loss: 0.3147394061088562 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [310/500], Loss: 0.31410157680511475 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [311/500], Loss: 0.3134668171405792 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [312/500], Loss: 0.3128352165222168 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [313/500], Loss: 0.3122066855430603 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [314/500], Loss: 0.31158125400543213 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [315/500], Loss: 0.3109588325023651 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [316/500], Loss: 0.3103395104408264 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [317/500], Loss: 0.3097231984138489 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [318/500], Loss: 0.3091098666191101 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [319/500], Loss: 0.3084994852542877 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [320/500], Loss: 0.3078920841217041 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [321/500], Loss: 0.3072875440120697 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [322/500], Loss: 0.30668601393699646 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [323/500], Loss: 0.30608731508255005 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [324/500], Loss: 0.30549150705337524 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [325/500], Loss: 0.30489858984947205 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [326/500], Loss: 0.3043084442615509 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [327/500], Loss: 0.3037211000919342 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [328/500], Loss: 0.30313658714294434 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [329/500], Loss: 0.30255481600761414 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [330/500], Loss: 0.3019758462905884 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [331/500], Loss: 0.3013995289802551 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [332/500], Loss: 0.3008260428905487 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [333/500], Loss: 0.30025514960289 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [334/500], Loss: 0.2996870279312134 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [335/500], Loss: 0.29912155866622925 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [336/500], Loss: 0.29855865240097046 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [337/500], Loss: 0.29799842834472656 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [338/500], Loss: 0.2974408268928528 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [339/500], Loss: 0.29688578844070435 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [340/500], Loss: 0.29633331298828125 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [341/500], Loss: 0.2957834303379059 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [342/500], Loss: 0.2952360510826111 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [343/500], Loss: 0.294691264629364 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [344/500], Loss: 0.29414892196655273 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [345/500], Loss: 0.29360905289649963 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [346/500], Loss: 0.2930716872215271 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [347/500], Loss: 0.29253676533699036 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [348/500], Loss: 0.2920042872428894 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [349/500], Loss: 0.29147425293922424 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [350/500], Loss: 0.2909466326236725 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [351/500], Loss: 0.29042136669158936 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [352/500], Loss: 0.28989848494529724 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [353/500], Loss: 0.28937798738479614 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [354/500], Loss: 0.2888597846031189 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [355/500], Loss: 0.2883439362049103 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [356/500], Loss: 0.2878303825855255 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [357/500], Loss: 0.2873191237449646 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [358/500], Loss: 0.28681015968322754 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [359/500], Loss: 0.28630349040031433 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [360/500], Loss: 0.2857990264892578 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [361/500], Loss: 0.28529679775238037 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [362/500], Loss: 0.28479689359664917 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [363/500], Loss: 0.2842990756034851 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [364/500], Loss: 0.2838035225868225 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [365/500], Loss: 0.2833101153373718 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [366/500], Loss: 0.28281888365745544 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [367/500], Loss: 0.2823297679424286 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [368/500], Loss: 0.2818428575992584 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [369/500], Loss: 0.281358003616333 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [370/500], Loss: 0.2808753252029419 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [371/500], Loss: 0.28039470314979553 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [372/500], Loss: 0.2799161970615387 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [373/500], Loss: 0.2794397175312042 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [374/500], Loss: 0.2789652943611145 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [375/500], Loss: 0.27849289774894714 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [376/500], Loss: 0.2780225872993469 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [377/500], Loss: 0.2775542438030243 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [378/500], Loss: 0.2770879566669464 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [379/500], Loss: 0.2766236364841461 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [380/500], Loss: 0.2761612832546234 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [381/500], Loss: 0.27570095658302307 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [382/500], Loss: 0.27524247765541077 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [383/500], Loss: 0.27478599548339844 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [384/500], Loss: 0.27433139085769653 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [385/500], Loss: 0.273878812789917 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [386/500], Loss: 0.2734280526638031 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [387/500], Loss: 0.272979199886322 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [388/500], Loss: 0.27253222465515137 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [389/500], Loss: 0.2720871567726135 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [390/500], Loss: 0.2716439366340637 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [391/500], Loss: 0.2712025046348572 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [392/500], Loss: 0.27076297998428345 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [393/500], Loss: 0.270325243473053 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [394/500], Loss: 0.2698892652988434 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [395/500], Loss: 0.2694551348686218 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [396/500], Loss: 0.2690228223800659 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [397/500], Loss: 0.2685922086238861 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [398/500], Loss: 0.26816344261169434 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [399/500], Loss: 0.26773637533187866 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [400/500], Loss: 0.267311155796051 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [401/500], Loss: 0.26688748598098755 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [402/500], Loss: 0.2664657235145569 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [403/500], Loss: 0.26604554057121277 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [404/500], Loss: 0.2656271457672119 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [405/500], Loss: 0.2652103900909424 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [406/500], Loss: 0.26479536294937134 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [407/500], Loss: 0.2643819749355316 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [408/500], Loss: 0.2639702260494232 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [409/500], Loss: 0.26356014609336853 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [410/500], Loss: 0.26315170526504517 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [411/500], Loss: 0.2627449333667755 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [412/500], Loss: 0.2623397409915924 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [413/500], Loss: 0.26193615794181824 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [414/500], Loss: 0.2615341544151306 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [415/500], Loss: 0.2611337900161743 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [416/500], Loss: 0.26073503494262695 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [417/500], Loss: 0.260337769985199 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [418/500], Loss: 0.25994211435317993 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [419/500], Loss: 0.25954800844192505 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [420/500], Loss: 0.2591554522514343 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [421/500], Loss: 0.25876444578170776 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [422/500], Loss: 0.2583748996257782 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [423/500], Loss: 0.2579869329929352 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [424/500], Loss: 0.25760048627853394 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [425/500], Loss: 0.2572154700756073 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [426/500], Loss: 0.25683197379112244 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [427/500], Loss: 0.25644999742507935 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [428/500], Loss: 0.25606948137283325 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [429/500], Loss: 0.25569039583206177 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [430/500], Loss: 0.25531280040740967 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [431/500], Loss: 0.2549366354942322 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [432/500], Loss: 0.2545618712902069 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [433/500], Loss: 0.254188597202301 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [434/500], Loss: 0.25381672382354736 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [435/500], Loss: 0.2534462511539459 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [436/500], Loss: 0.2530772089958191 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [437/500], Loss: 0.2527095377445221 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [438/500], Loss: 0.25234323740005493 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [439/500], Loss: 0.25197833776474 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [440/500], Loss: 0.2516148090362549 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [441/500], Loss: 0.2512527108192444 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [442/500], Loss: 0.25089186429977417 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [443/500], Loss: 0.2505324184894562 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [444/500], Loss: 0.250174343585968 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [445/500], Loss: 0.2498176097869873 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [446/500], Loss: 0.24946212768554688 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [447/500], Loss: 0.24910800158977509 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [448/500], Loss: 0.24875518679618835 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [449/500], Loss: 0.24840369820594788 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [450/500], Loss: 0.24805346131324768 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [451/500], Loss: 0.24770455062389374 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [452/500], Loss: 0.2473568618297577 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [453/500], Loss: 0.24701054394245148 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [454/500], Loss: 0.24666544795036316 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [455/500], Loss: 0.24632160365581512 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [456/500], Loss: 0.24597899615764618 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [457/500], Loss: 0.2456376850605011 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [458/500], Loss: 0.2452975958585739 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [459/500], Loss: 0.24495871365070343 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [460/500], Loss: 0.24462103843688965 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [461/500], Loss: 0.24428462982177734 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [462/500], Loss: 0.24394941329956055 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [463/500], Loss: 0.24361543357372284 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [464/500], Loss: 0.24328260123729706 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [465/500], Loss: 0.24295100569725037 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [466/500], Loss: 0.2426205426454544 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [467/500], Loss: 0.24229130148887634 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [468/500], Loss: 0.241963192820549 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [469/500], Loss: 0.24163632094860077 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [470/500], Loss: 0.24131055176258087 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [471/500], Loss: 0.2409859448671341 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [472/500], Loss: 0.24066245555877686 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [473/500], Loss: 0.24034015834331512 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [474/500], Loss: 0.24001899361610413 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [475/500], Loss: 0.23969891667366028 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [476/500], Loss: 0.23937997221946716 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [477/500], Loss: 0.23906216025352478 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [478/500], Loss: 0.23874545097351074 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [479/500], Loss: 0.23842982947826385 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [480/500], Loss: 0.2381153404712677 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [481/500], Loss: 0.2378019094467163 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [482/500], Loss: 0.23748958110809326 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [483/500], Loss: 0.23717835545539856 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [484/500], Loss: 0.23686818778514862 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [485/500], Loss: 0.23655907809734344 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [486/500], Loss: 0.23625102639198303 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [487/500], Loss: 0.23594403266906738 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [488/500], Loss: 0.2356381118297577 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [489/500], Loss: 0.23533323407173157 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [490/500], Loss: 0.23502936959266663 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [491/500], Loss: 0.23472651839256287 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [492/500], Loss: 0.23442475497722626 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [493/500], Loss: 0.23412398993968964 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [494/500], Loss: 0.23382428288459778 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [495/500], Loss: 0.23352551460266113 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [496/500], Loss: 0.23322781920433044 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [497/500], Loss: 0.23293109238147736 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [498/500], Loss: 0.23263540863990784 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [499/500], Loss: 0.23234069347381592 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Epoch [500/500], Loss: 0.2320469319820404 Training accuracy = 0.949999988079071 | Test accuracy = 0.8999999761581421\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# rf.fit(train, labels_train)\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.05\n",
    "num_epochs = 500\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "train = train.float()\n",
    "test = test.float()\n",
    "labels_train = labels_train.float()\n",
    "labels_test = labels_test.float()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model.forward(train)\n",
    "    loss = loss_fn(outputs, labels_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Calculate training and validation accuracy every epoch\n",
    "    training_accuracy = 0\n",
    "    test_accuracy = 0\n",
    "     \n",
    "    model.eval()\n",
    "    outputs = model.predict(train)\n",
    "    training_accuracy = (outputs == labels_train).float().mean()\n",
    "    outputs = model.predict(test)\n",
    "    test_accuracy = (outputs == labels_test).float().mean()\n",
    "    #print('Training accuracy = {} | Test accuracy = {}'.format(training_accuracy, test_accuracy))\n",
    "    \n",
    "    # Print the loss every epoch\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}' + ' Training accuracy = {} | Test accuracy = {}'.format(training_accuracy, test_accuracy))\n",
    "        \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn.metrics.accuracy_score(labels_test, rf.predict(test))\n",
    "\n",
    "sklearn.metrics.accuracy_score(labels_test, model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(train.numpy(),\n",
    "                                                   feature_names=feature_names,\n",
    "                                                   class_names=target_names,\n",
    "                                                   discretize_continuous=False,\n",
    "                                                   sample_around_instance=True)\n",
    "\n",
    "# Create funcction to pass to explainer.explain_instance\n",
    "apply_model_predict = lambda x: model.class_probabilities(torch.from_numpy(x).float()).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an instance to explain\n",
    "i_explained = np.random.randint(0, test.shape[0])\n",
    "\n",
    "exp = explainer.explain_instance(test[i_explained].numpy(), apply_model_predict, num_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients of LIME explanation\n",
    "coefficients_map = exp.local_exp[1]\n",
    "feature_index = [elem[0] for elem in coefficients_map]\n",
    "LIME_coefficients = [coefficients_map[i][1] for i in feature_index]\n",
    "LIME_intercept = exp.intercept[1]\n",
    "\n",
    "\n",
    "# Compute the rescaled LIME coefficients\n",
    "# See https://github.com/marcotcr/lime/issues/113\n",
    "beta0 = LIME_intercept\n",
    "beta1 = LIME_coefficients[0]\n",
    "beta2 = LIME_coefficients[1]\n",
    "\n",
    "mu1 = explainer.scaler.mean_[0]\n",
    "mu2 = explainer.scaler.mean_[1]\n",
    "\n",
    "sigma1 = explainer.scaler.scale_[0]\n",
    "sigma2 = explainer.scaler.scale_[1]\n",
    "\n",
    "beta0_rescaled = beta0 - beta1*mu1/sigma1 - beta2*mu2/sigma2\n",
    "beta1_rescaled = beta1/sigma1\n",
    "beta2_rescaled = beta2/sigma2\n",
    "\n",
    "# Create decision boundary\n",
    "decision_boundary_LIME = lambda x : (0.5-beta0_rescaled)/beta2_rescaled - x*beta1_rescaled/beta2_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients of original model and create decision boundary\n",
    "coefficients = model.linear.weight.detach().numpy()\n",
    "biases = model.linear.bias.detach().numpy()\n",
    "decision_boundary = lambda x : (-biases)/coefficients[0][1] - x*coefficients[0][0]/coefficients[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0, 10, 100)\n",
    "y = decision_boundary(x)\n",
    "y_LIME = decision_boundary_LIME(x)\n",
    "\n",
    "features_test = test.numpy() if not isinstance(test, np.ndarray) else test\n",
    "labels_test = labels_test.numpy() if not isinstance(labels_test, np.ndarray) else labels_test\n",
    "\n",
    "# Plotting the decision boundary and the test set\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, y_LIME, linestyle = '--')\n",
    "ix0 = (labels_test == 0).ravel()\n",
    "ix1 = (labels_test == 1).ravel()\n",
    "plt.scatter(features_test[ix0,0], features_test[ix0, 1], c = 'b', label = target_names[0])\n",
    "plt.scatter(features_test[ix1,0], features_test[ix1, 1], c = 'g', label = target_names[1])\n",
    "point_explained = features_test[i_explained,:]\n",
    "circle = plt.Circle(point_explained, 0.1, color='r', fill=False)\n",
    "plt.gca().add_patch(circle)\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0, 10)\n",
    "plt.xlabel(feature_names[0])\n",
    "plt.ylabel(feature_names[1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIME_coefficients:\n",
      "petal length (cm): -0.033147797220563824\n",
      "petal width (cm): -0.558205612340186\n",
      "Black box model prediction: 0.1285\n",
      "LIME model prediction: 0.1935\n"
     ]
    }
   ],
   "source": [
    "# Print LIME coefficients\n",
    "print(\"LIME_coefficients:\")\n",
    "for feature, coefficient in zip(feature_names, [beta1_rescaled, beta2_rescaled]):\n",
    "    print(f\"{feature}: {coefficient}\")\n",
    "\n",
    "# Black box model\n",
    "f = lambda x: model.class_probabilities(torch.from_numpy(x).float().reshape(-1,2))[0][1].numpy()\n",
    "\n",
    "# LIME model\n",
    "g = lambda x: beta0_rescaled + beta1_rescaled*x[0] + beta2_rescaled*x[1]\n",
    "\n",
    "# Print black box model and LIME model prediction\n",
    "print(f\"Black box model prediction: {f(point_explained):.4f}\")\n",
    "print(f\"LIME model prediction: {g(point_explained):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXPLORERvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
