{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_score, recall_score\n",
    "\n",
    "import data\n",
    "reload(data)\n",
    "from data import AmlsimDataset\n",
    "\n",
    "import modules\n",
    "reload(modules)\n",
    "from modules import GCN, GCN_GNNExplainer, GCN_GraphSVX\n",
    "from modules import GraphSAGE\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "traindata = AmlsimDataset(node_file='data/simulation2/swedbank/train/nodes.csv', edge_file='data/simulation2/swedbank/train/edges.csv', node_features=True, node_labels=True).get_data()\n",
    "testdata = AmlsimDataset(node_file='data/simulation2/swedbank/test/nodes.csv', edge_file='data/simulation2/swedbank/test/edges.csv', node_features=True, node_labels=True).get_data()\n",
    "traindata = traindata.to(device)\n",
    "testdata = testdata.to(device)\n",
    "\n",
    "# # Convert label tensors to one-hot encoded form\n",
    "# traindata.y = F.one_hot(traindata.y, num_classes=2)\n",
    "# testdata.y = F.one_hot(testdata.y, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "mean = traindata.x.mean(dim=0, keepdim=True)\n",
    "std = traindata.x.std(dim=0, keepdim=True)\n",
    "traindata.x = (traindata.x - mean) / std\n",
    "testdata.x = (testdata.x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN_GraphSVX(\n",
       "  (convs): ModuleList(\n",
       "    (0): GCNConv(10, 16)\n",
       "    (1): GCNConv(16, 16)\n",
       "    (2): GCNConv(16, 2)\n",
       "  )\n",
       "  (bns): ModuleList(\n",
       "    (0-1): 2 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model\n",
    "input_dim = 10\n",
    "hidden_dim = 16\n",
    "output_dim = 2\n",
    "n_layers = 3\n",
    "dropout = 0.3\n",
    "model = GCN_GraphSVX(input_dim, hidden_dim, output_dim, n_layers, dropout)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(model.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: -0.5064, precision: 0.3680, recall: 0.2771\n",
      "epoch: 20, loss: -0.5379, precision: 0.5000, recall: 0.1928\n",
      "epoch: 30, loss: -0.5867, precision: 0.6047, recall: 0.1566\n",
      "epoch: 40, loss: -0.6238, precision: 0.7714, recall: 0.1627\n",
      "epoch: 50, loss: -0.6495, precision: 0.8378, recall: 0.1867\n",
      "epoch: 60, loss: -0.6695, precision: 0.8378, recall: 0.1867\n",
      "epoch: 70, loss: -0.6855, precision: 0.8333, recall: 0.1807\n",
      "epoch: 80, loss: -0.6970, precision: 0.8333, recall: 0.1807\n",
      "epoch: 90, loss: -0.7066, precision: 0.8571, recall: 0.1807\n",
      "epoch: 100, loss: -0.7138, precision: 0.8571, recall: 0.1807\n",
      "epoch: 110, loss: -0.7189, precision: 0.8571, recall: 0.1807\n",
      "epoch: 120, loss: -0.7229, precision: 0.8571, recall: 0.1807\n",
      "epoch: 130, loss: -0.7261, precision: 0.8788, recall: 0.1747\n",
      "epoch: 140, loss: -0.7283, precision: 0.8788, recall: 0.1747\n",
      "epoch: 150, loss: -0.7298, precision: 0.8710, recall: 0.1627\n",
      "epoch: 160, loss: -0.7318, precision: 0.8750, recall: 0.1687\n",
      "epoch: 170, loss: -0.7333, precision: 0.8750, recall: 0.1687\n",
      "epoch: 180, loss: -0.7345, precision: 0.8750, recall: 0.1687\n",
      "epoch: 190, loss: -0.7352, precision: 0.8485, recall: 0.1687\n",
      "epoch: 200, loss: -0.7359, precision: 0.8235, recall: 0.1687\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model.forward(traindata.x, traindata.edge_index)\n",
    "    loss = criterion(out, traindata.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model.forward(testdata.x, testdata.edge_index)\n",
    "            loss = criterion(out, testdata.y)\n",
    "            precision = precision_score(testdata.y.cpu().numpy(), out.cpu().numpy().argmax(axis=1), zero_division=0)\n",
    "            recall = recall_score(testdata.y.cpu().numpy(), out.cpu().numpy().argmax(axis=1), zero_division=0)\n",
    "            print(f'epoch: {epoch + 1}, loss: {loss:.4f}, precision: {precision:.4f}, recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[394   6]\n",
      " [138  28]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.forward(testdata.x, testdata.edge_index)\n",
    "    y_pred = out.cpu().numpy().argmax(axis=1)\n",
    "    y_true = testdata.y.cpu().numpy()\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_function(y, args_train_ratio=0.6, seed=10):\n",
    "    return _get_train_val_test_masks(y.shape[0], y, (1-args_train_ratio)/2, (1-args_train_ratio), seed=seed)\n",
    "\n",
    "def _get_train_val_test_masks(total_size, y_true, val_fraction, test_fraction, seed):\n",
    "    \"\"\"Performs stratified train/test/val split\n",
    "\n",
    "    Args:\n",
    "        total_size (int): dataset total number of instances\n",
    "        y_true (numpy array): labels\n",
    "        val_fraction (int): validation/test set proportion\n",
    "        test_fraction (int): test and val sets proportion\n",
    "        seed (int): seed value\n",
    "\n",
    "    Returns:\n",
    "        [torch.tensors]: train, validation and test masks - boolean values\n",
    "    \"\"\"\n",
    "    # Split into a train, val and test set\n",
    "    # Store indexes of the nodes belong to train, val and test set\n",
    "    indexes = range(total_size)\n",
    "    indexes_train, indexes_test = train_test_split(\n",
    "        indexes, test_size=test_fraction, stratify=y_true, random_state=seed)\n",
    "    indexes_train, indexes_val = train_test_split(indexes_train, test_size=val_fraction, stratify=y_true[indexes_train],\n",
    "                                                  random_state=seed)\n",
    "    # Init masks\n",
    "    train_idxs = np.zeros(total_size, dtype=bool)\n",
    "    val_idxs = np.zeros(total_size, dtype=bool)\n",
    "    test_idxs = np.zeros(total_size, dtype=bool)\n",
    "\n",
    "    # Update masks using corresponding indexes\n",
    "    train_idxs[indexes_train] = True\n",
    "    val_idxs[indexes_val] = True\n",
    "    test_idxs[indexes_test] = True\n",
    "\n",
    "    return torch.from_numpy(train_idxs), torch.from_numpy(val_idxs), torch.from_numpy(test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "train_ratio = 0.8\n",
    "testdata.to('cpu')\n",
    "model.to('cpu')\n",
    "\n",
    "data = SimpleNamespace()\n",
    "data.x = testdata.x\n",
    "data.edge_index  = testdata.edge_index\n",
    "data.y = testdata.y\n",
    "data.num_classes = 2\n",
    "data.num_features = 10\n",
    "data.num_nodes = testdata.x.shape[0]\n",
    "data.name = 'test'\n",
    "data.train_mask, data.val_mask, data.test_mask = split_function(data.y.numpy(), train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GraphSVX_explainers\n",
    "reload(GraphSVX_explainers)\n",
    "\n",
    "from GraphSVX_explainers import GraphSVX, GraphLIME\n",
    "\n",
    "\n",
    "explainer = GraphSVX(data, model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainations only consider node features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 70.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WLS: Matrix not invertible\n",
      "r2:  0.9962832860625991\n",
      "weighted r2:  0.9999896247863371\n",
      "Explanations include 10 node features and 0 neighbours for this node        for 2 classes\n",
      "Model prediction is class 0 with confidence 2.5924456119537354, while true label is 0\n",
      "Base value 2.646485242351872 for class  0\n",
      "Weights for node features:  -0.05403806267895561 and neighbours:  0\n",
      "Most influential features:  [(7, 0.9804937226581387), (6, -0.8046020945766941), (4, -0.3630704879760742)]\n",
      "Time:  0.1974503993988037\n",
      "Explainations only consider node features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [00:00, 66.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WLS: Matrix not invertible\n",
      "r2:  0.9076794462848671\n",
      "weighted r2:  0.9999153460950052\n",
      "Explanations include 9 node features and 0 neighbours for this node        for 2 classes\n",
      "Model prediction is class 0 with confidence 2.5759079456329346, while true label is 0\n",
      "Base value 2.646421509595487 for class  0\n",
      "Weights for node features:  -0.07051832590635199 and neighbours:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most influential features:  [(2, -0.050754356547258794), (6, 0.0358568653558371), (0, -0.026760444045066833)]\n",
      "Time:  0.4112105369567871\n",
      "Explainations only consider node features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 67.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WLS: Matrix not invertible\n",
      "r2:  0.9905563185613565\n",
      "weighted r2:  0.9999906458962867\n",
      "Explanations include 9 node features and 0 neighbours for this node        for 2 classes\n",
      "Model prediction is class 0 with confidence 2.66753888130188, while true label is 0\n",
      "Base value 2.646414899518356 for class  0\n",
      "Weights for node features:  0.021123667128062573 and neighbours:  0\n",
      "Most influential features:  [(9, 0.03273194625398901), (1, -0.015139260549403843), (5, 0.004650397431285924)]\n",
      "Time:  0.6110687255859375\n",
      "Explainations only consider node features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 61.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WLS: Matrix not invertible\n",
      "r2:  0.9949677113369303\n",
      "weighted r2:  0.9999828091567446\n",
      "Explanations include 9 node features and 0 neighbours for this node        for 2 classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction is class 0 with confidence 2.666609287261963, while true label is 0\n",
      "Base value 2.646312785500621 for class  0\n",
      "Weights for node features:  0.020295840814287924 and neighbours:  0\n",
      "Most influential features:  [(9, 0.08223654709581751), (8, 0.03657207960714004), (0, -0.03450490057002753)]\n",
      "Time:  0.8360488414764404\n",
      "Explainations only consider node features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 71.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WLS: Matrix not invertible\n",
      "r2:  0.8714810347181036\n",
      "weighted r2:  0.9995736284195016\n",
      "Explanations include 9 node features and 0 neighbours for this node        for 2 classes\n",
      "Model prediction is class 0 with confidence 2.6664745807647705, while true label is 0\n",
      "Base value 2.6463108725140962 for class  0\n",
      "Weights for node features:  0.020161201086009495 and neighbours:  0\n",
      "Most influential features:  [(9, 0.05009955660352716), (7, -0.01732225705540813), (8, -0.010469432938619017)]\n",
      "Time:  1.0562725067138672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "explanations = explainer.explain(node_indexes=range(10,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXPLORERvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
