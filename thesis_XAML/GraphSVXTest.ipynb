{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_score, recall_score\n",
    "\n",
    "import data\n",
    "reload(data)\n",
    "from data import AmlsimDataset\n",
    "\n",
    "import modules\n",
    "reload(modules)\n",
    "from modules import GCN, GCN_GNNExplainer, GCN_GraphSVX\n",
    "from modules import GraphSAGE\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "traindata = AmlsimDataset(node_file='data/simulation2/swedbank/train/nodes.csv', edge_file='data/simulation2/swedbank/train/edges.csv', node_features=True, node_labels=True).get_data()\n",
    "testdata = AmlsimDataset(node_file='data/simulation2/swedbank/test/nodes.csv', edge_file='data/simulation2/swedbank/test/edges.csv', node_features=True, node_labels=True).get_data()\n",
    "traindata = traindata.to(device)\n",
    "testdata = testdata.to(device)\n",
    "\n",
    "# # Convert label tensors to one-hot encoded form\n",
    "# traindata.y = F.one_hot(traindata.y, num_classes=2)\n",
    "# testdata.y = F.one_hot(testdata.y, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "mean = traindata.x.mean(dim=0, keepdim=True)\n",
    "std = traindata.x.std(dim=0, keepdim=True)\n",
    "traindata.x = (traindata.x - mean) / std\n",
    "testdata.x = (testdata.x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN_GraphSVX(\n",
       "  (convs): ModuleList(\n",
       "    (0): GCNConv(10, 16)\n",
       "    (1): GCNConv(16, 16)\n",
       "    (2): GCNConv(16, 2)\n",
       "  )\n",
       "  (bns): ModuleList(\n",
       "    (0-1): 2 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model\n",
    "input_dim = 10\n",
    "hidden_dim = 16\n",
    "output_dim = 2\n",
    "n_layers = 3\n",
    "dropout = 0.3\n",
    "model = GCN_GraphSVX(input_dim, hidden_dim, output_dim, n_layers, dropout)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(model.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: -0.5610, precision: 0.5000, recall: 0.0723\n",
      "epoch: 20, loss: -0.6158, precision: 0.5600, recall: 0.0843\n",
      "epoch: 30, loss: -0.6563, precision: 0.7442, recall: 0.1928\n",
      "epoch: 40, loss: -0.6841, precision: 0.7805, recall: 0.1928\n",
      "epoch: 50, loss: -0.7004, precision: 0.7714, recall: 0.1627\n",
      "epoch: 60, loss: -0.7099, precision: 0.7941, recall: 0.1627\n",
      "epoch: 70, loss: -0.7175, precision: 0.8438, recall: 0.1627\n",
      "epoch: 80, loss: -0.7230, precision: 0.8438, recall: 0.1627\n",
      "epoch: 90, loss: -0.7270, precision: 0.8710, recall: 0.1627\n",
      "epoch: 100, loss: -0.7295, precision: 0.8710, recall: 0.1627\n",
      "epoch: 110, loss: -0.7325, precision: 0.8485, recall: 0.1687\n",
      "epoch: 120, loss: -0.7343, precision: 0.8485, recall: 0.1687\n",
      "epoch: 130, loss: -0.7359, precision: 0.8485, recall: 0.1687\n",
      "epoch: 140, loss: -0.7372, precision: 0.8485, recall: 0.1687\n",
      "epoch: 150, loss: -0.7381, precision: 0.7949, recall: 0.1867\n",
      "epoch: 160, loss: -0.7387, precision: 0.7949, recall: 0.1867\n",
      "epoch: 170, loss: -0.7395, precision: 0.7949, recall: 0.1867\n",
      "epoch: 180, loss: -0.7399, precision: 0.7949, recall: 0.1867\n",
      "epoch: 190, loss: -0.7400, precision: 0.7805, recall: 0.1928\n",
      "epoch: 200, loss: -0.7404, precision: 0.7556, recall: 0.2048\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model.forward(traindata.x, traindata.edge_index)\n",
    "    loss = criterion(out, traindata.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model.forward(testdata.x, testdata.edge_index)\n",
    "            loss = criterion(out, testdata.y)\n",
    "            precision = precision_score(testdata.y.cpu().numpy(), out.cpu().numpy().argmax(axis=1), zero_division=0)\n",
    "            recall = recall_score(testdata.y.cpu().numpy(), out.cpu().numpy().argmax(axis=1), zero_division=0)\n",
    "            print(f'epoch: {epoch + 1}, loss: {loss:.4f}, precision: {precision:.4f}, recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[389  11]\n",
      " [132  34]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.forward(testdata.x, testdata.edge_index)\n",
    "    y_pred = out.cpu().numpy().argmax(axis=1)\n",
    "    y_true = testdata.y.cpu().numpy()\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_function(y, args_train_ratio=0.6, seed=10):\n",
    "    return _get_train_val_test_masks(y.shape[0], y, (1-args_train_ratio)/2, (1-args_train_ratio), seed=seed)\n",
    "\n",
    "def _get_train_val_test_masks(total_size, y_true, val_fraction, test_fraction, seed):\n",
    "    \"\"\"Performs stratified train/test/val split\n",
    "\n",
    "    Args:\n",
    "        total_size (int): dataset total number of instances\n",
    "        y_true (numpy array): labels\n",
    "        val_fraction (int): validation/test set proportion\n",
    "        test_fraction (int): test and val sets proportion\n",
    "        seed (int): seed value\n",
    "\n",
    "    Returns:\n",
    "        [torch.tensors]: train, validation and test masks - boolean values\n",
    "    \"\"\"\n",
    "    # Split into a train, val and test set\n",
    "    # Store indexes of the nodes belong to train, val and test set\n",
    "    indexes = range(total_size)\n",
    "    indexes_train, indexes_test = train_test_split(\n",
    "        indexes, test_size=test_fraction, stratify=y_true, random_state=seed)\n",
    "    indexes_train, indexes_val = train_test_split(indexes_train, test_size=val_fraction, stratify=y_true[indexes_train],\n",
    "                                                  random_state=seed)\n",
    "    # Init masks\n",
    "    train_idxs = np.zeros(total_size, dtype=bool)\n",
    "    val_idxs = np.zeros(total_size, dtype=bool)\n",
    "    test_idxs = np.zeros(total_size, dtype=bool)\n",
    "\n",
    "    # Update masks using corresponding indexes\n",
    "    train_idxs[indexes_train] = True\n",
    "    val_idxs[indexes_val] = True\n",
    "    test_idxs[indexes_test] = True\n",
    "\n",
    "    return torch.from_numpy(train_idxs), torch.from_numpy(val_idxs), torch.from_numpy(test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "train_ratio = 0.8\n",
    "testdata.to('cpu')\n",
    "model.to('cpu')\n",
    "\n",
    "data = SimpleNamespace()\n",
    "data.x = testdata.x\n",
    "data.edge_index  = testdata.edge_index\n",
    "data.y = testdata.y\n",
    "data.num_classes = 2\n",
    "data.num_features = 10\n",
    "data.num_nodes = testdata.x.shape[0]\n",
    "data.name = 'test'\n",
    "data.train_mask, data.val_mask, data.test_mask = split_function(data.y.numpy(), train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GraphSVX_explainers\n",
    "reload(GraphSVX_explainers)\n",
    "\n",
    "from GraphSVX_explainers import GraphSVX, GraphLIME\n",
    "\n",
    "\n",
    "explainer = GraphSVX(data, model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 75.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WLS: Matrix not invertible\n",
      "r2:  0.49901398812245956\n",
      "weighted r2:  0.9858230765409469\n",
      "Explanations include 8 node features and 2 neighbours for this node        for 2 classes\n",
      "Model prediction is class 0 with confidence 2.7114129066467285, while true label is 1\n",
      "Base value 2.622413944548696 for class  0\n",
      "Weights for node features:  0.21191291898552578 and neighbours:  -0.12296751529356698\n",
      "Most influential features:  [(8, -0.538347544557837), (4, 0.4769126772880554), (3, 0.16716720163822174)]\n",
      "Time:  0.19017815589904785\n",
      "Sum explanations:  [0.0889454036919588]\n",
      "Base value:  [2.6224086345959376, 2.622411509629994, 2.6224120983794696, 2.622399734699588, 2.6224035582503227, 2.622413944548696]\n",
      "Model class probabilities:  {tensor([0.9975, 0.0025], grad_fn=<SelectBackward0>)}\n",
      "True label = 1\n"
     ]
    }
   ],
   "source": [
    "explanations = explainer.explain(node_indexes=[318])\n",
    "print('Sum explanations: ', [np.sum(explanation) for explanation in explanations])\n",
    "print('Base value: ', explainer.base_values)\n",
    "\n",
    "model = model.to('cpu')\n",
    "print(f'Model class probabilities: ',{model.forward(testdata.x.to('cpu'), testdata.edge_index.to('cpu'))[318]})\n",
    "print(f'True label = {testdata.y[318]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXPLORERvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
