{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_score, recall_score\n",
    "\n",
    "import data\n",
    "reload(data)\n",
    "from data import AmlsimDataset\n",
    "\n",
    "import modules\n",
    "reload(modules)\n",
    "from modules import GCN\n",
    "from modules import GraphSAGE\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m traindata \u001b[38;5;241m=\u001b[39m AmlsimDataset(node_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/simulation2/swedbank/train/nodes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, edge_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/simulation2/swedbank/train/edges.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, node_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, node_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mget_data()\n\u001b[1;32m      3\u001b[0m testdata \u001b[38;5;241m=\u001b[39m AmlsimDataset(node_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/simulation2/swedbank/test/nodes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, edge_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/simulation2/swedbank/test/edges.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, node_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, node_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mget_data()\n\u001b[0;32m----> 4\u001b[0m traindata \u001b[38;5;241m=\u001b[39m \u001b[43mtraindata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m      5\u001b[0m testdata \u001b[38;5;241m=\u001b[39m testdata\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# # Convert label tensors to one-hot encoded form\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# traindata.y = F.one_hot(traindata.y, num_classes=2)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# testdata.y = F.one_hot(testdata.y, num_classes=2)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "traindata = AmlsimDataset(node_file='data/simulation2/swedbank/train/nodes.csv', edge_file='data/simulation2/swedbank/train/edges.csv', node_features=True, node_labels=True).get_data()\n",
    "testdata = AmlsimDataset(node_file='data/simulation2/swedbank/test/nodes.csv', edge_file='data/simulation2/swedbank/test/edges.csv', node_features=True, node_labels=True).get_data()\n",
    "traindata = traindata.to(device)\n",
    "testdata = testdata.to(device)\n",
    "\n",
    "# # Convert label tensors to one-hot encoded form\n",
    "# traindata.y = F.one_hot(traindata.y, num_classes=2)\n",
    "# testdata.y = F.one_hot(testdata.y, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Normalize data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[43mtraindata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m std \u001b[38;5;241m=\u001b[39m traindata\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mstd(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m traindata\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m (traindata\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m-\u001b[39m mean) \u001b[38;5;241m/\u001b[39m std\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "mean = traindata.x.mean(dim=0, keepdim=True)\n",
    "std = traindata.x.std(dim=0, keepdim=True)\n",
    "traindata.x = (traindata.x - mean) / std\n",
    "testdata.x = (testdata.x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (convs): ModuleList(\n",
       "    (0): GCNConv(10, 16)\n",
       "    (1): GCNConv(16, 16)\n",
       "    (2): GCNConv(16, 2)\n",
       "  )\n",
       "  (bns): ModuleList(\n",
       "    (0-1): 2 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model\n",
    "input_dim = 10\n",
    "hidden_dim = 16\n",
    "output_dim = 2\n",
    "n_layers = 3\n",
    "dropout = 0.3\n",
    "model = GCN(input_dim, hidden_dim, output_dim, n_layers, dropout)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(model.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 0.5409, precision: 0.7500, recall: 0.1627\n",
      "epoch: 20, loss: 0.5411, precision: 0.7714, recall: 0.1627\n",
      "epoch: 30, loss: 0.5402, precision: 0.7568, recall: 0.1687\n",
      "epoch: 40, loss: 0.5380, precision: 0.7632, recall: 0.1747\n",
      "epoch: 50, loss: 0.5378, precision: 0.7576, recall: 0.1506\n",
      "epoch: 60, loss: 0.5366, precision: 0.7442, recall: 0.1928\n",
      "epoch: 70, loss: 0.5365, precision: 0.7442, recall: 0.1928\n",
      "epoch: 80, loss: 0.5371, precision: 0.7317, recall: 0.1807\n",
      "epoch: 90, loss: 0.5358, precision: 0.7500, recall: 0.1807\n",
      "epoch: 100, loss: 0.5338, precision: 0.7143, recall: 0.2108\n",
      "epoch: 110, loss: 0.5315, precision: 0.6792, recall: 0.2169\n",
      "epoch: 120, loss: 0.5346, precision: 0.6875, recall: 0.1988\n",
      "epoch: 130, loss: 0.5367, precision: 0.7111, recall: 0.1928\n",
      "epoch: 140, loss: 0.5355, precision: 0.7174, recall: 0.1988\n",
      "epoch: 150, loss: 0.5341, precision: 0.7174, recall: 0.1988\n",
      "epoch: 160, loss: 0.5333, precision: 0.6875, recall: 0.1988\n",
      "epoch: 170, loss: 0.5325, precision: 0.6800, recall: 0.2048\n",
      "epoch: 180, loss: 0.5298, precision: 0.6939, recall: 0.2048\n",
      "epoch: 190, loss: 0.5292, precision: 0.6939, recall: 0.2048\n",
      "epoch: 200, loss: 0.5306, precision: 0.6939, recall: 0.2048\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(traindata)\n",
    "    loss = criterion(out, traindata.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(testdata)\n",
    "            loss = criterion(out, testdata.y)\n",
    "            precision = precision_score(testdata.y.cpu().numpy(), out.cpu().numpy().argmax(axis=1), zero_division=0)\n",
    "            recall = recall_score(testdata.y.cpu().numpy(), out.cpu().numpy().argmax(axis=1), zero_division=0)\n",
    "            print(f'epoch: {epoch + 1}, loss: {loss:.4f}, precision: {precision:.4f}, recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[385  15]\n",
      " [132  34]]\n",
      "Number of labels equal to 0: 400\n",
      "Number of labels equal to 1: 166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(testdata)\n",
    "    y_pred = out.cpu().numpy().argmax(axis=1)\n",
    "    y_true = testdata.y.cpu().numpy()\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GraphSAGE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m traindata \u001b[38;5;241m=\u001b[39m AmlsimDataset(node_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/simulation2/swedbank/train/nodes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, edge_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/simulation2/swedbank/train/edges.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, node_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, node_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mget_data()\n\u001b[1;32m      6\u001b[0m testdata \u001b[38;5;241m=\u001b[39m AmlsimDataset(node_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/simulation2/swedbank/test/nodes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, edge_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/simulation2/swedbank/test/edges.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, node_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, node_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mget_data()\n\u001b[0;32m----> 7\u001b[0m traindata \u001b[38;5;241m=\u001b[39m \u001b[43mtraindata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m      8\u001b[0m testdata \u001b[38;5;241m=\u001b[39m testdata\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# normalize features\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device('cuda:0')\n",
    "    \n",
    "# data\n",
    "traindata = AmlsimDataset(node_file='data/simulation2/swedbank/train/nodes.csv', edge_file='data/simulation2/swedbank/train/edges.csv', node_features=True, node_labels=True).get_data()\n",
    "testdata = AmlsimDataset(node_file='data/simulation2/swedbank/test/nodes.csv', edge_file='data/simulation2/swedbank/test/edges.csv', node_features=True, node_labels=True).get_data()\n",
    "traindata = traindata.to(device)\n",
    "testdata = testdata.to(device)\n",
    "    \n",
    "# normalize features\n",
    "mean = traindata.x.mean(dim=0, keepdim=True)\n",
    "std = traindata.x.std(dim=0, keepdim=True)\n",
    "traindata.x = (traindata.x - mean) / std\n",
    "testdata.x = (testdata.x - mean) / std\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(traindata))\n",
    "\n",
    "# create dataloader\n",
    "batch_size = 64\n",
    "trainloader = DataLoader(traindata, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(testdata, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "#print train_loader\n",
    "print(len(trainloader))\n",
    "\n",
    "# model\n",
    "input_dim = 10\n",
    "hidden_dim = 65\n",
    "output_dim = 2\n",
    "dropout = 0.07279450042274103\n",
    "model = GraphSAGE(input_dim, hidden_dim, output_dim, dropout)\n",
    "model.to(device)\n",
    "    \n",
    "# optimizer\n",
    "lr = 0.010353064733105691\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "# loss function\n",
    "beta = 0.9999999914740594\n",
    "n_samples_per_classes = [(traindata.y == 0).sum().item(), (traindata.y == 1).sum().item()]\n",
    "\n",
    "#add weights\n",
    "criterion = torch.nn.CrossEntropyLoss()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrainloader\u001b[49m:\n\u001b[1;32m      4\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      5\u001b[0m         out \u001b[38;5;241m=\u001b[39m model(traindata)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    for batch in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(traindata)\n",
    "        loss = criterion(out, traindata.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                out = model(testdata)\n",
    "                loss = criterion(out, testdata.y)\n",
    "                accuracy = accuracy_score(testdata.y.cpu().numpy(), out.cpu().numpy().argmax(axis=1))\n",
    "                balanced_accuracy = balanced_accuracy_score(testdata.y.cpu().numpy(), out.cpu().numpy().argmax(axis=1))\n",
    "                precision = precision_score(testdata.y.cpu().numpy(), out.cpu().numpy().argmax(axis=1), zero_division=0)\n",
    "                recall = recall_score(testdata.y.cpu().numpy(), out.cpu().numpy().argmax(axis=1), zero_division=0)\n",
    "                f1 = f1_score(testdata.y.cpu().numpy(), out.cpu().numpy().argmax(axis=1), zero_division=0)\n",
    "                print(f'epoch: {epoch + 1}, loss: {loss:.4f}, accuracy: {accuracy:.4f}, balanced_accuracy: {balanced_accuracy:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, f1: {f1:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXPLORERvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
