{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flib.preprocess.feature_engineering import cal_features\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import multiprocessing as mp\n",
    "from flib.federated_learning.modules import LogisticRegressor\n",
    "from flib.federated_learning.criterions import ClassBalancedLoss\n",
    "from flib.federated_learning.client import Client\n",
    "from flib.federated_learning.server import Server\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed:int=1):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    ## NOTE: If you want every run to be exactly the same each time\n",
    "    ##       uncomment the following lines\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set seed and multiprocessing context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(42)\n",
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = '/home/edvin/Desktop/flib/'\n",
    "config_path = pwd + 'flib/AMLsim/paramFiles/10K_accts/conf.json'\n",
    "\n",
    "os.system(f'cd ../flib/AMLsim && python3 scripts/transaction_graph_generator.py \"{config_path}\"')\n",
    "os.system(f'cd ../flib/AMLsim && mvn exec:java -Dexec.mainClass=amlsim.AMLSim -Dexec.args=\"{config_path}\"')\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "tx_log_path = os.path.join(config['output']['directory'], config['general']['simulation_name'], config['output']['transaction_log'])\n",
    "\n",
    "print(f'txs log: {tx_log_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_log_path = 'outputs/10K_accts/tx_log.csv'\n",
    "dfs = cal_features('../flib/AMLsim/' + tx_log_path, windows=(3, 10), overlap=0.9, include_edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for df in dfs:\n",
    "    train_df, test_df = df\n",
    "    train_node_df, train_edge_df = train_df\n",
    "    test_node_df, test_edge_df = test_df\n",
    "    display(train_node_df.loc[0:0])\n",
    "    train_node_df = train_node_df.drop(columns=['account', 'bank'])\n",
    "    test_node_df = test_node_df.drop(columns=['account', 'bank'])\n",
    "    datasets.append((train_node_df, test_node_df))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "log_predictions = True\n",
    "n_rounds = 301\n",
    "eval_every = 30\n",
    "n_rounds_no_aggregation = 0\n",
    "Module = LogisticRegressor \n",
    "Optimizer = torch.optim.SGD\n",
    "Criterion = ClassBalancedLoss\n",
    "n_epochs = 1 \n",
    "batch_size = 128\n",
    "n_workers = 4\n",
    "optimizer_params = {'momentum': 0.0, 'dampening': 0.0, 'weight_decay': 0.0}\n",
    "criterion_params = {'beta': 0.9999, 'loss_type': 'sigmoid'}\n",
    "lr = 0.001\n",
    "\n",
    "os.makedirs(f'results/10K_accts', exist_ok=True)\n",
    "    \n",
    "# init clients\n",
    "clients = []\n",
    "for i, dataset in enumerate(datasets):\n",
    "    trainset, testset = dataset\n",
    "    clients.append(Client(\n",
    "        name=f'client_{i}',\n",
    "        device=torch.device('cuda:0'),\n",
    "        trainset=trainset,\n",
    "        valset=None, \n",
    "        testset=testset, \n",
    "        Module=Module, \n",
    "        Optimizer=Optimizer, \n",
    "        Criterion=Criterion, \n",
    "        optimizer_params=optimizer_params,\n",
    "        criterion_params=criterion_params,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        batch_size=batch_size\n",
    "    ))\n",
    "    \n",
    "# init server\n",
    "input_dim = len(datasets[0][0].columns) - 1\n",
    "output_dim = len(datasets[0][0][datasets[0][0].columns[-1]].unique())\n",
    "module = Module(input_dim=input_dim, output_dim=output_dim)\n",
    "model = module.state_dict()\n",
    "server = Server(clients=clients, model=model, n_workers=n_workers, log_predictions=log_predictions, log_file=f'results/10K_accts/log')\n",
    "    \n",
    "# train\n",
    "print(f'running experiment: 10K_accts')\n",
    "avg_losses = server.run(n_rounds=n_rounds, eval_every=eval_every, n_rounds_no_aggregation=n_rounds_no_aggregation)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
